{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03-models_pretrained_and_more.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"GO6YjFoAA6ET","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"dd7f8c8d-3f57-4cf7-a434-389d50e475c0","executionInfo":{"status":"ok","timestamp":1553050379585,"user_tz":-540,"elapsed":28079,"user":{"displayName":"はぎ","photoUrl":"","userId":"03923874740366966476"}}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"5t9g-EMdA7J8","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","path = \"/content/gdrive/My Drive/Colab Notebooks\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"3GTewYR0BMLi","colab_type":"code","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":88},"outputId":"3075d5d8-3bbe-46ea-f8e3-47892264592d","executionInfo":{"status":"ok","timestamp":1553050506978,"user_tz":-540,"elapsed":10619,"user":{"displayName":"はぎ","photoUrl":"","userId":"03923874740366966476"}}},"cell_type":"code","source":["from google.colab import files\n","files.upload()"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-eed8da1f-11b0-495b-823a-6cae39325071\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-eed8da1f-11b0-495b-823a-6cae39325071\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving kaggle.json to kaggle.json\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'kaggle.json': b'{\"username\":\"komiyamori\",\"key\":\"35c790e377b5498f22cc4a26949cfd95\"}'}"]},"metadata":{"tags":[]},"execution_count":10}]},{"metadata":{"id":"6VAaf4ThBjUQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"02448915-2af6-4bdf-cebe-ebe82ac37287","executionInfo":{"status":"ok","timestamp":1553050562253,"user_tz":-540,"elapsed":10255,"user":{"displayName":"はぎ","photoUrl":"","userId":"03923874740366966476"}}},"cell_type":"code","source":["!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!pip install kaggle\n","!chmod 600 /root/.kaggle/kaggle.json"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.3)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.3.9)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.0)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n","Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n"],"name":"stdout"}]},{"metadata":{"id":"NenxRykUBu2a","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"outputId":"51200a7c-2e18-4312-bd73-5c7e612218d0","executionInfo":{"status":"ok","timestamp":1553050572718,"user_tz":-540,"elapsed":9433,"user":{"displayName":"はぎ","photoUrl":"","userId":"03923874740366966476"}}},"cell_type":"code","source":["#実行する前にカグルのダウンロードオールとか押して認証をおkしておく\n","!kaggle competitions download -c tgs-salt-identification-challenge"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Downloading depths.csv to /content\n","\r  0% 0.00/322k [00:00<?, ?B/s]\n","100% 322k/322k [00:00<00:00, 44.5MB/s]\n","Downloading sample_submission.csv to /content\n","  0% 0.00/264k [00:00<?, ?B/s]\n","100% 264k/264k [00:00<00:00, 81.3MB/s]\n","Downloading train.csv to /content\n","  0% 0.00/922k [00:00<?, ?B/s]\n","100% 922k/922k [00:00<00:00, 60.7MB/s]\n","Downloading test.zip to /content\n"," 98% 160M/163M [00:01<00:00, 65.7MB/s]\n","100% 163M/163M [00:01<00:00, 93.4MB/s]\n","Downloading train.zip to /content\n"," 58% 22.0M/37.9M [00:00<00:00, 33.6MB/s]\n","100% 37.9M/37.9M [00:00<00:00, 95.9MB/s]\n"],"name":"stdout"}]},{"metadata":{"id":"iRiYayT3Bzem","colab_type":"code","colab":{}},"cell_type":"code","source":["#解凍\n","!unzip test.zip -d test\n","!unzip train.zip -d train"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yi8fmXMw27_M","colab_type":"text"},"cell_type":"markdown","source":["## Model architecture tuning & score optimization\n","\n","\n","Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n","\n","Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n","\n","For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n","In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n","\n","ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."]},{"metadata":{"id":"7Ey8hT-T27_O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"18908a16-45bd-42da-e9c1-a482a3d3e7e9","executionInfo":{"status":"ok","timestamp":1553049967077,"user_tz":-540,"elapsed":2552,"user":{"displayName":"はぎ","photoUrl":"","userId":"03923874740366966476"}}},"cell_type":"code","source":["import gc\n","import glob\n","import os\n","\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from tqdm import tqdm\n","\n","from keras import optimizers\n","from keras.callbacks import *\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","from keras.layers import *\n","from keras.models import Model, load_model, save_model\n","from keras.preprocessing.image import array_to_img, img_to_array, load_img\n","from keras.applications.resnet50 import ResNet50, preprocess_input\n","\n","%matplotlib inline"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"hmRJyPWk27_b","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.rcParams['figure.figsize'] = (12, 9)\n","# plt.style.use('ggplot')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JWP6uBHV27_h","colab_type":"code","colab":{}},"cell_type":"code","source":["def compute_coverage(df, masks):\n","    \n","    df = df.copy()\n","    \n","    def cov_to_class(val):\n","        for i in range(0, 11):\n","            if val * 10 <= i:\n","                return i\n","\n","    # Output percentage of area covered by class\n","    df['coverage'] = np.mean(masks, axis=(1, 2))\n","    # Coverage must be split into bins, otherwise stratified split will not be possible,\n","    # because each coverage will occur only once.\n","    df['coverage_class'] = df.coverage.map(\n","        cov_to_class)\n","\n","    return df\n","\n","\n","def create_depth_abs_channels(image_tensor):\n","    image_tensor = image_tensor.astype(np.float32)\n","    h, w, c = image_tensor.shape\n","    for row, const in enumerate(np.linspace(0, 1, h)):\n","        image_tensor[row, :, 1] = const\n","    image_tensor[:, :, 2] = (\n","        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n","\n","    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n","    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n","    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n","    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n","    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n","\n","    return image_tensor"],"execution_count":0,"outputs":[]},{"metadata":{"id":"t9W0TBFh27_o","colab_type":"text"},"cell_type":"markdown","source":["### Data loading & depth merge:"]},{"metadata":{"id":"pBgMgoieAH7C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"47d3f7c5-48c4-4cec-8b03-62b5e8a3553e","executionInfo":{"status":"ok","timestamp":1553050638056,"user_tz":-540,"elapsed":1122,"user":{"displayName":"はぎ","photoUrl":"","userId":"03923874740366966476"}}},"cell_type":"code","source":["pwd"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"]},"metadata":{"tags":[]},"execution_count":16}]},{"metadata":{"id":"g8lrR8dG27_q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"975a5e70-ad7d-4795-ec0f-96b309b72ed2","executionInfo":{"status":"ok","timestamp":1553050710556,"user_tz":-540,"elapsed":830,"user":{"displayName":"はぎ","photoUrl":"","userId":"03923874740366966476"}}},"cell_type":"code","source":["train = pd.read_csv('train.csv')\n","test = pd.read_csv('sample_submission.csv')\n","depth = pd.read_csv('depths.csv')\n","\n","train_src = 'train/'\n","\n","print('train:\\n{}'.format(train.head()))\n","print('\\ntest:\\n{}'.format(test.head()))\n","\n","\n","train = train.merge(depth, how='left', on='id')\n","test = test.merge(depth, how='left', on='id')\n","\n","print('\\n{}'.format(train.head()))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["train:\n","           id                                           rle_mask\n","0  575d24d81d                                                NaN\n","1  a266a2a9df                                          5051 5151\n","2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n","3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n","4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n","\n","test:\n","           id rle_mask\n","0  155410d6fa      1 1\n","1  78b32781d1      1 1\n","2  63db2a476a      1 1\n","3  17bfcdb967      1 1\n","4  7ea0fd3c88      1 1\n","\n","           id                                           rle_mask    z\n","0  575d24d81d                                                NaN  843\n","1  a266a2a9df                                          5051 5151  794\n","2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n","3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n","4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"],"name":"stdout"}]},{"metadata":{"id":"pInShUhY27_w","colab_type":"text"},"cell_type":"markdown","source":["### Load images and masks, examine random sample:"]},{"metadata":{"id":"bKRcnkP027_y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"0ea54a55-ca57-4e9d-d115-4c21f06f90f3","executionInfo":{"status":"ok","timestamp":1553050728263,"user_tz":-540,"elapsed":3224,"user":{"displayName":"はぎ","photoUrl":"","userId":"03923874740366966476"}}},"cell_type":"code","source":["X_train = np.asarray(\n","    [cv2.imread('train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n","    dtype=np.uint8) / 255.\n","y_train = np.asarray(\n","    [cv2.imread('train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n","    dtype=np.uint8) / 255.\n","\n","print(X_train.shape, y_train.shape)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["(4000, 101, 101) (4000, 101, 101)\n"],"name":"stdout"}]},{"metadata":{"scrolled":true,"id":"Jh-jIDCR27__","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":372},"outputId":"ae687801-b385-4791-a4f3-31a64a2c8ba8","executionInfo":{"status":"ok","timestamp":1553050813203,"user_tz":-540,"elapsed":1184,"user":{"displayName":"はぎ","photoUrl":"","userId":"03923874740366966476"}}},"cell_type":"code","source":["random_index = np.random.randint(0, X_train.shape[0])\n","\n","fig, ax = plt.subplots(1, 2)\n","\n","ax[0].imshow(X_train[random_index], cmap='gray')\n","ax[1].imshow(y_train[random_index], cmap='gray')"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f65037c0a20>"]},"metadata":{"tags":[]},"execution_count":25},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAsoAAAFSCAYAAADrS/nzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndV8AAAAASUVORK5CYII=\n","text/plain":["<Figure size 864x648 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"IoCExwZi28A3","colab_type":"text"},"cell_type":"markdown","source":["### Compute salt coverage (this will serve as a basis for stratified split):"]},{"metadata":{"id":"X8DbTyVR28A5","colab_type":"code","colab":{}},"cell_type":"code","source":["train = compute_coverage(train, y_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EODEwUcs28A8","colab_type":"text"},"cell_type":"markdown","source":["### Prepare data for training:"]},{"metadata":{"id":"PaXwE_Yi28A-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"a4e70dae-123b-4a49-d58b-2ca5e3ca1965","executionInfo":{"status":"ok","timestamp":1553051274280,"user_tz":-540,"elapsed":20088,"user":{"displayName":"はぎ","photoUrl":"","userId":"03923874740366966476"}}},"cell_type":"code","source":["kfold = StratifiedKFold(n_splits=5, random_state=1337)\n","\n","# Add channel features\n","X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n","X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n","\n","# Resize to 224x224, default ResNet50 image size\n","X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n","y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n","\n","\n","for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n","    \n","    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n","    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n","    \n","    break\n","    \n","\n","y_tr = np.expand_dims(y_tr, axis=-1)\n","y_val = np.expand_dims(y_val, axis=-1)\n","\n","print(X_tr.shape, y_tr.shape)\n","print(X_val.shape, y_val.shape)\n","\n","\n","del X_train_ch, y_resized\n","del X_resized\n","gc.collect()"],"execution_count":27,"outputs":[{"output_type":"stream","text":["(3196, 224, 224, 3) (3196, 224, 224, 1)\n","(804, 224, 224, 3) (804, 224, 224, 1)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["340"]},"metadata":{"tags":[]},"execution_count":27}]},{"metadata":{"id":"x1BDvi7e28BC","colab_type":"text"},"cell_type":"markdown","source":["### Loss functions & metric:"]},{"metadata":{"id":"ZoL34V6f28BF","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.losses import binary_crossentropy\n","\n","\n","# Dice & combined\n","def dice_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred = K.cast(y_pred, 'float32')\n","    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n","    intersection = y_true_f * y_pred_f\n","    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n","    return score\n","\n","\n","def dice_loss(y_true, y_pred):\n","    smooth = 1.\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = y_true_f * y_pred_f\n","    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","    return 1. - score\n","\n","\n","def bce_dice_loss(y_true, y_pred):\n","    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n","\n","\n","def bce_logdice_loss(y_true, y_pred):\n","    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n","\n","\n","\n","# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n","def lovasz_grad(gt_sorted):\n","    \"\"\"\n","    Computes gradient of the Lovasz extension w.r.t sorted errors\n","    See Alg. 1 in paper\n","    \"\"\"\n","    gts = tf.reduce_sum(gt_sorted)\n","    intersection = gts - tf.cumsum(gt_sorted)\n","    union = gts + tf.cumsum(1. - gt_sorted)\n","    jaccard = 1. - intersection / union\n","    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n","    return jaccard\n","\n","\n","# --------------------------- BINARY LOSSES ---------------------------\n","\n","def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n","    \"\"\"\n","    Binary Lovasz hinge loss\n","      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n","      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n","      per_image: compute the loss per image instead of per batch\n","      ignore: void class id\n","    \"\"\"\n","    if per_image:\n","        def treat_image(log_lab):\n","            log, lab = log_lab\n","            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n","            log, lab = flatten_binary_scores(log, lab, ignore)\n","            return lovasz_hinge_flat(log, lab)\n","        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n","        loss = tf.reduce_mean(losses)\n","    else:\n","        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n","    return loss\n","\n","\n","def lovasz_hinge_flat(logits, labels):\n","    \"\"\"\n","    Binary Lovasz hinge loss\n","      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n","      labels: [P] Tensor, binary ground truth labels (0 or 1)\n","      ignore: label to ignore\n","    \"\"\"\n","\n","    def compute_loss():\n","        labelsf = tf.cast(labels, logits.dtype)\n","        signs = 2. * labelsf - 1.\n","        errors = 1. - logits * tf.stop_gradient(signs)\n","        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n","        gt_sorted = tf.gather(labelsf, perm)\n","        grad = lovasz_grad(gt_sorted)\n","        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n","        return loss\n","\n","    # deal with the void prediction case (only void pixels)\n","    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n","                   lambda: tf.reduce_sum(logits) * 0.,\n","                   compute_loss,\n","                   strict=True,\n","                   name=\"loss\"\n","                   )\n","    return loss\n","\n","\n","def flatten_binary_scores(scores, labels, ignore=None):\n","    \"\"\"\n","    Flattens predictions in the batch (binary case)\n","    Remove labels equal to 'ignore'\n","    \"\"\"\n","    scores = tf.reshape(scores, (-1,))\n","    labels = tf.reshape(labels, (-1,))\n","    if ignore is None:\n","        return scores, labels\n","    valid = tf.not_equal(labels, ignore)\n","    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n","    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n","    return vscores, vlabels\n","\n","\n","def lovasz_loss(y_true, y_pred):\n","    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n","    #logits = K.log(y_pred / (1. - y_pred))\n","    logits = y_pred #Jiaxin\n","    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n","    return loss\n","\n","\n","# IoU metric for observation during training\n","# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n","def get_iou_vector(A, B):\n","    # Numpy version    \n","    batch_size = A.shape[0]\n","    metric = 0.0\n","    for batch in range(batch_size):\n","        t, p = A[batch], B[batch]\n","        true = np.sum(t)\n","        pred = np.sum(p)\n","        \n","        # deal with empty mask first\n","        if true == 0:\n","            metric += (pred == 0)\n","            continue\n","        \n","        # non empty mask case.  Union is never empty \n","        # hence it is safe to divide by its number of pixels\n","        intersection = np.sum(t * p)\n","        union = true + pred - intersection\n","        iou = intersection / union\n","        \n","        # iou metrric is a stepwise approximation of the real iou over 0.5\n","        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n","        \n","        metric += iou\n","        \n","    # teake the average over all images in batch\n","    metric /= batch_size\n","    return metric\n","\n","\n","def my_iou_metric(label, pred):\n","    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n","\n","\n","# For Lovash loss\n","def my_iou_metric_2(label, pred):\n","    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"boU5uJbu28BQ","colab_type":"text"},"cell_type":"markdown","source":["### Encoder features - ResNet50:\n","\n","In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n","Default input size will be assumed, which is (224, 224, 3).\n","Layers will be as follows:\n","\n","- 'activation_1', shape: (None, 112, 112, 64)\n","- 'activation_10', shape: (None, 56, 56, 256)\n","- 'activation_22', shape: (None, 28, 28, 512)\n","- 'activation_40', shape: (None, 14, 14, 1024)\n","- 'activation_49', shape: (None, 7, 7, 2048)\n","\n","One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."]},{"metadata":{"id":"d0K6TpIs28Bh","colab_type":"raw"},"cell_type":"markdown","source":["base_model = ResNet50(input_shape=input_size, include_top=False)\n","base_model.summary()"]},{"metadata":{"id":"t-ACEdIk28Bv","colab_type":"text"},"cell_type":"markdown","source":["### Decoder blocks:\n","\n","Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n","For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."]},{"metadata":{"id":"Wm4OMNfI28Bx","colab_type":"code","colab":{}},"cell_type":"code","source":["# Basic decoder block with Conv, BN and PReLU activation.\n","def decoder_block_simple(\n","        layer_name, block_name,\n","        num_filters=32,\n","        conv_dim=(3, 3)):\n","\n","    x_dec = Conv2D(\n","        num_filters, conv_dim,\n","        padding='same',\n","        name='{}_conv'.format(block_name))(layer_name)\n","    x_dec = BatchNormalization(\n","        name='{}_bn'.format(block_name))(x_dec)\n","    x_dec = PReLU(\n","        name='{}_activation'.format(block_name))(x_dec)\n","\n","    return x_dec\n","\n","# Decoder block with bottleneck architecture, where middle conv layer\n","# is half the size of first and last, in order to compress representation.\n","# This type of architecture is supposed to retain most useful information.\n","def decoder_block_bottleneck(\n","        layer_name, block_name,\n","        num_filters=32,\n","        conv_dim=(3, 3),\n","        dropout_frac=0.2):\n","#デコーダーブロックのコンボリューションが３つ\n","    x_dec = Conv2D(\n","        num_filters, conv_dim,\n","        padding='same',\n","        name='{}_conv1'.format(block_name))(layer_name)\n","    x_dec = BatchNormalization(\n","        name='{}_bn1'.format(block_name))(x_dec)\n","    x_dec = PReLU(\n","        name='{}_activation1'.format(block_name))(x_dec)\n","    x_dec = Dropout(dropout_frac)(x_dec)\n","\n","    x_dec2 = Conv2D(\n","        num_filters // 2, conv_dim,\n","        padding='same',\n","        name='{}_conv2'.format(block_name))(x_dec)\n","    x_dec2 = BatchNormalization(\n","        name='{}_bn2'.format(block_name))(x_dec2)\n","    x_dec2 = PReLU(\n","        name='{}_activation2'.format(block_name))(x_dec2)\n","    x_dec2 = Dropout(dropout_frac)(x_dec2)\n","\n","    x_dec2 = Conv2D(\n","        num_filters, conv_dim,\n","        padding='same',\n","        name='{}_conv3'.format(block_name))(x_dec2)\n","    x_dec2 = BatchNormalization(\n","        name='{}_bn3'.format(block_name))(x_dec2)\n","    x_dec2 = PReLU(\n","        name='{}_activation3'.format(block_name))(x_dec2)\n","    x_dec2 = Dropout(dropout_frac)(x_dec2)\n","\n","    x_dec2 = Add()([x_dec, x_dec2])\n","\n","    return x_dec2"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CN5ZL7VA28CD","colab_type":"text"},"cell_type":"markdown","source":["### Model definition:\n","\n","Combine encoder and decoder blocks to create final segmentation model."]},{"metadata":{"id":"wLJ7zGX728CF","colab_type":"code","colab":{}},"cell_type":"code","source":["# Model is parametrized in a way to enable easy change of decoder_block type,\n","# as this is an argument that can be given a function, like decoder_block_simple.\n","def unet_resnet(input_size, decoder_block,\n","                weights='imagenet',\n","                loss_func='binary_crossentropy',\n","                metrics_list=[my_iou_metric],\n","                use_lovash=False):\n","\n","    # Base model - encoder\n","    base_model = ResNet50(\n","        input_shape=input_size, \n","        include_top=False,\n","        weights=weights)\n","    \n","    # Layers for feature extraction in the encoder part\n","    encoder1 = base_model.get_layer('activation_1').output\n","    encoder2 = base_model.get_layer('activation_10').output\n","    encoder3 = base_model.get_layer('activation_22').output\n","    encoder4 = base_model.get_layer('activation_40').output\n","    encoder5 = base_model.get_layer('activation_49').output\n","\n","    # Center block\n","    center = decoder_block(\n","        encoder5, 'center', num_filters=512)\n","    concat5 = concatenate([center, encoder5], axis=-1)\n","\n","    # Decoder part.\n","    # Every decoder block processed concatenated output from encoder and decoder part.\n","    # This creates skip connections.\n","    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n","    decoder4 = decoder_block(\n","        concat5, 'decoder4', num_filters=256)\n","    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n","\n","    decoder3 = decoder_block(\n","        concat4, 'decoder3', num_filters=128)\n","    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n","\n","    decoder2 = decoder_block(\n","        concat3, 'decoder2', num_filters=64)\n","    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n","\n","    decoder1 = decoder_block(\n","        concat2, 'decoder1', num_filters=64)\n","    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n","\n","    # Final upsampling and decoder block for segmentation.\n","    output = UpSampling2D()(concat1)\n","    output = decoder_block(\n","        output, 'decoder_output', num_filters=32)\n","    output = Conv2D(\n","        1, (1, 1), activation=None, name='prediction')(output)\n","    if not use_lovash:\n","        output = Activation('sigmoid')(output)\n","        \n","    model = Model(base_model.input, output)\n","    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n","\n","    return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"42dhgFOW28CT","colab_type":"text"},"cell_type":"markdown","source":["### Inspect created model:"]},{"metadata":{"scrolled":true,"id":"p9cwtQTF28CW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":7755},"outputId":"6ed7e950-39b3-424d-8a83-9b707d3b038b","executionInfo":{"status":"ok","timestamp":1553051312891,"user_tz":-540,"elapsed":18401,"user":{"displayName":"はぎ","photoUrl":"","userId":"03923874740366966476"}}},"cell_type":"code","source":["input_size = (224, 224, 3)\n","\n","K.clear_session()\n","model = unet_resnet(\n","    input_size, decoder_block_simple, weights='imagenet')\n","model.summary()"],"execution_count":31,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n","  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94658560/94653016 [==============================] - 4s 0us/step\n","WARNING:tensorflow:From <ipython-input-28-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, use\n","    tf.py_function, which takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    \n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n","__________________________________________________________________________________________________\n","res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n","                                                                 bn2a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n","                                                                 activation_7[0][0]               \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n","                                                                 bn3a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n","                                                                 activation_13[0][0]              \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n","                                                                 activation_16[0][0]              \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n","                                                                 activation_19[0][0]              \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n","                                                                 bn4a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n","                                                                 activation_25[0][0]              \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n","                                                                 activation_28[0][0]              \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n","                                                                 activation_31[0][0]              \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n","                                                                 activation_34[0][0]              \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n","__________________________________________________________________________________________________\n","res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n","                                                                 activation_37[0][0]              \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n","__________________________________________________________________________________________________\n","res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n","                                                                 bn5a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n","__________________________________________________________________________________________________\n","res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n","                                                                 activation_43[0][0]              \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n","__________________________________________________________________________________________________\n","res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n","                                                                 activation_46[0][0]              \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n","__________________________________________________________________________________________________\n","center_conv (Conv2D)            (None, 7, 7, 512)    9437696     activation_49[0][0]              \n","__________________________________________________________________________________________________\n","center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n","__________________________________________________________________________________________________\n","center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           center_activation[0][0]          \n","                                                                 activation_49[0][0]              \n","__________________________________________________________________________________________________\n","decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n","__________________________________________________________________________________________________\n","decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n","__________________________________________________________________________________________________\n","up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n","                                                                 activation_40[0][0]              \n","__________________________________________________________________________________________________\n","decoder3_conv (Conv2D)          (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n","__________________________________________________________________________________________________\n","decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n","__________________________________________________________________________________________________\n","up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n","                                                                 activation_22[0][0]              \n","__________________________________________________________________________________________________\n","decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n","__________________________________________________________________________________________________\n","decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n","__________________________________________________________________________________________________\n","up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n","__________________________________________________________________________________________________\n","concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n","                                                                 activation_10[0][0]              \n","__________________________________________________________________________________________________\n","decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n","__________________________________________________________________________________________________\n","decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n","__________________________________________________________________________________________________\n","decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n","__________________________________________________________________________________________________\n","up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n","                                                                 activation_1[0][0]               \n","__________________________________________________________________________________________________\n","up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n","__________________________________________________________________________________________________\n","decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n","__________________________________________________________________________________________________\n","decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n","__________________________________________________________________________________________________\n","prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n","__________________________________________________________________________________________________\n","activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n","==================================================================================================\n","Total params: 42,912,065\n","Trainable params: 42,856,833\n","Non-trainable params: 55,232\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"nzJK0BfQ28Cj","colab_type":"text"},"cell_type":"markdown","source":["### Train model:"]},{"metadata":{"scrolled":true,"id":"sjyDfXPk28Cm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":11121},"outputId":"c5e78bfe-e226-439f-d4d5-d79209cb1560","executionInfo":{"status":"ok","timestamp":1553060227075,"user_tz":-540,"elapsed":5071210,"user":{"displayName":"はぎ","photoUrl":"","userId":"03923874740366966476"}}},"cell_type":"code","source":["K.clear_session()\n","\n","# Build model:\n","# Here, you can experiment with various losses.\n","# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n","# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n","# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n","# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n","# This is controlled by use_lovash parameter.\n","model_depth = unet_resnet(\n","    input_size, decoder_block_bottleneck, weights='imagenet',\n","    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n","    use_lovash=False)\n","print(model_depth.summary())\n","\n","\n","model_checkpoint = ModelCheckpoint(\n","    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n","    save_best_only=True, save_weights_only=True, verbose=1)\n","reduce_lr = ReduceLROnPlateau(\n","    monitor='val_my_iou_metric',\n","    mode='max',\n","    factor=0.5, \n","    patience=5, \n","    min_lr=0.0001, \n","    verbose=1)\n","\n","\n","epochs = 20  # 25\n","batch_size = 16\n","\n","history = model_depth.fit(X_tr, y_tr,\n","                    validation_data=[X_val, y_val], \n","                    epochs=epochs,\n","                    batch_size=batch_size,\n","                    callbacks=[model_checkpoint,reduce_lr], \n","                    verbose=1)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n","  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"],"name":"stderr"},{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n","__________________________________________________________________________________________________\n","res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n","                                                                 bn2a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n","                                                                 activation_7[0][0]               \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n","                                                                 bn3a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n","                                                                 activation_13[0][0]              \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n","                                                                 activation_16[0][0]              \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n","                                                                 activation_19[0][0]              \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n","                                                                 bn4a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n","                                                                 activation_25[0][0]              \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n","                                                                 activation_28[0][0]              \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n","                                                                 activation_31[0][0]              \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n","                                                                 activation_34[0][0]              \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n","__________________________________________________________________________________________________\n","res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n","                                                                 activation_37[0][0]              \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n","__________________________________________________________________________________________________\n","res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n","                                                                 bn5a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n","__________________________________________________________________________________________________\n","res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n","                                                                 activation_43[0][0]              \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n","__________________________________________________________________________________________________\n","res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n","                                                                 activation_46[0][0]              \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n","__________________________________________________________________________________________________\n","center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     activation_49[0][0]              \n","__________________________________________________________________________________________________\n","center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n","__________________________________________________________________________________________________\n","center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n","__________________________________________________________________________________________________\n","center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n","__________________________________________________________________________________________________\n","center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n","__________________________________________________________________________________________________\n","center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n","__________________________________________________________________________________________________\n","center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n","__________________________________________________________________________________________________\n","add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n","                                                                 dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n","                                                                 activation_49[0][0]              \n","__________________________________________________________________________________________________\n","decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n","__________________________________________________________________________________________________\n","decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n","__________________________________________________________________________________________________\n","decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n","__________________________________________________________________________________________________\n","decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n","__________________________________________________________________________________________________\n","decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n","__________________________________________________________________________________________________\n","decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n","__________________________________________________________________________________________________\n","decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n","__________________________________________________________________________________________________\n","dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n","__________________________________________________________________________________________________\n","add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n","                                                                 dropout_6[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n","                                                                 activation_40[0][0]              \n","__________________________________________________________________________________________________\n","decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n","__________________________________________________________________________________________________\n","decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n","__________________________________________________________________________________________________\n","dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n","__________________________________________________________________________________________________\n","decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n","__________________________________________________________________________________________________\n","decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n","__________________________________________________________________________________________________\n","decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n","__________________________________________________________________________________________________\n","dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n","__________________________________________________________________________________________________\n","decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n","__________________________________________________________________________________________________\n","decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n","__________________________________________________________________________________________________\n","decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n","__________________________________________________________________________________________________\n","dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n","__________________________________________________________________________________________________\n","add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n","                                                                 dropout_9[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n","                                                                 activation_22[0][0]              \n","__________________________________________________________________________________________________\n","decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n","__________________________________________________________________________________________________\n","decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n","__________________________________________________________________________________________________\n","dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n","__________________________________________________________________________________________________\n","decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n","__________________________________________________________________________________________________\n","decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n","__________________________________________________________________________________________________\n","decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n","__________________________________________________________________________________________________\n","dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n","__________________________________________________________________________________________________\n","decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n","__________________________________________________________________________________________________\n","decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n","__________________________________________________________________________________________________\n","decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n","__________________________________________________________________________________________________\n","dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n","__________________________________________________________________________________________________\n","add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n","                                                                 dropout_12[0][0]                 \n","__________________________________________________________________________________________________\n","up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n","__________________________________________________________________________________________________\n","concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n","                                                                 activation_10[0][0]              \n","__________________________________________________________________________________________________\n","decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n","__________________________________________________________________________________________________\n","decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n","__________________________________________________________________________________________________\n","decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n","__________________________________________________________________________________________________\n","dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n","__________________________________________________________________________________________________\n","decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n","__________________________________________________________________________________________________\n","decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n","__________________________________________________________________________________________________\n","decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n","__________________________________________________________________________________________________\n","dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n","__________________________________________________________________________________________________\n","decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n","__________________________________________________________________________________________________\n","decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n","__________________________________________________________________________________________________\n","decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n","__________________________________________________________________________________________________\n","dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n","__________________________________________________________________________________________________\n","add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n","                                                                 dropout_15[0][0]                 \n","__________________________________________________________________________________________________\n","up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n","                                                                 activation_1[0][0]               \n","__________________________________________________________________________________________________\n","up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n","__________________________________________________________________________________________________\n","decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n","__________________________________________________________________________________________________\n","decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n","__________________________________________________________________________________________________\n","dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n","__________________________________________________________________________________________________\n","decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n","__________________________________________________________________________________________________\n","decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n","__________________________________________________________________________________________________\n","decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n","__________________________________________________________________________________________________\n","dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n","__________________________________________________________________________________________________\n","decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n","__________________________________________________________________________________________________\n","decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n","__________________________________________________________________________________________________\n","decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n","__________________________________________________________________________________________________\n","dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n","__________________________________________________________________________________________________\n","add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n","                                                                 dropout_18[0][0]                 \n","__________________________________________________________________________________________________\n","prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n","__________________________________________________________________________________________________\n","activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n","==================================================================================================\n","Total params: 48,978,353\n","Trainable params: 48,919,953\n","Non-trainable params: 58,400\n","__________________________________________________________________________________________________\n","None\n","Train on 3196 samples, validate on 804 samples\n","Epoch 1/20\n","3196/3196 [==============================] - 285s 89ms/step - loss: 0.7711 - my_iou_metric: 0.2747 - val_loss: 3.2550 - val_my_iou_metric: 0.1114\n","\n","Epoch 00001: val_my_iou_metric improved from -inf to 0.11144, saving model to unet_resnet.h5\n","Epoch 2/20\n","3196/3196 [==============================] - 247s 77ms/step - loss: 0.6016 - my_iou_metric: 0.4560 - val_loss: 2.7165 - val_my_iou_metric: 0.1007\n","\n","Epoch 00002: val_my_iou_metric did not improve from 0.11144\n","Epoch 3/20\n","3196/3196 [==============================] - 246s 77ms/step - loss: 0.5369 - my_iou_metric: 0.5091 - val_loss: 0.6063 - val_my_iou_metric: 0.5000\n","\n","Epoch 00003: val_my_iou_metric improved from 0.11144 to 0.50000, saving model to unet_resnet.h5\n","Epoch 4/20\n","3196/3196 [==============================] - 246s 77ms/step - loss: 0.4900 - my_iou_metric: 0.5435 - val_loss: 0.4251 - val_my_iou_metric: 0.6199\n","\n","Epoch 00004: val_my_iou_metric improved from 0.50000 to 0.61990, saving model to unet_resnet.h5\n","Epoch 5/20\n","3196/3196 [==============================] - 247s 77ms/step - loss: 0.4591 - my_iou_metric: 0.5660 - val_loss: 0.4511 - val_my_iou_metric: 0.6045\n","\n","Epoch 00005: val_my_iou_metric did not improve from 0.61990\n","Epoch 6/20\n","3196/3196 [==============================] - 247s 77ms/step - loss: 0.4351 - my_iou_metric: 0.6022 - val_loss: 0.7265 - val_my_iou_metric: 0.5041\n","\n","Epoch 00006: val_my_iou_metric did not improve from 0.61990\n","Epoch 7/20\n","3196/3196 [==============================] - 247s 77ms/step - loss: 0.4184 - my_iou_metric: 0.6134 - val_loss: 0.4965 - val_my_iou_metric: 0.5859\n","\n","Epoch 00007: val_my_iou_metric did not improve from 0.61990\n","Epoch 8/20\n","3196/3196 [==============================] - 248s 77ms/step - loss: 0.3853 - my_iou_metric: 0.6305 - val_loss: 0.7758 - val_my_iou_metric: 0.2888\n","\n","Epoch 00008: val_my_iou_metric did not improve from 0.61990\n","Epoch 9/20\n","3196/3196 [==============================] - 247s 77ms/step - loss: 0.3873 - my_iou_metric: 0.6375 - val_loss: 0.8853 - val_my_iou_metric: 0.3359\n","\n","Epoch 00009: val_my_iou_metric did not improve from 0.61990\n","\n","Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","Epoch 10/20\n","3196/3196 [==============================] - 246s 77ms/step - loss: 0.3431 - my_iou_metric: 0.6589 - val_loss: 0.3704 - val_my_iou_metric: 0.6688\n","\n","Epoch 00010: val_my_iou_metric improved from 0.61990 to 0.66878, saving model to unet_resnet.h5\n","Epoch 11/20\n","3196/3196 [==============================] - 245s 77ms/step - loss: 0.3375 - my_iou_metric: 0.6733 - val_loss: 0.3200 - val_my_iou_metric: 0.7015\n","\n","Epoch 00011: val_my_iou_metric improved from 0.66878 to 0.70149, saving model to unet_resnet.h5\n","Epoch 12/20\n","3196/3196 [==============================] - 245s 77ms/step - loss: 0.3050 - my_iou_metric: 0.6811 - val_loss: 0.4032 - val_my_iou_metric: 0.6950\n","\n","Epoch 00012: val_my_iou_metric did not improve from 0.70149\n","Epoch 13/20\n","3196/3196 [==============================] - 245s 77ms/step - loss: 0.3036 - my_iou_metric: 0.6729 - val_loss: 0.3539 - val_my_iou_metric: 0.6708\n","\n","Epoch 00013: val_my_iou_metric did not improve from 0.70149\n","Epoch 14/20\n","3196/3196 [==============================] - 246s 77ms/step - loss: 0.2829 - my_iou_metric: 0.6903 - val_loss: 0.3900 - val_my_iou_metric: 0.6545\n","\n","Epoch 00014: val_my_iou_metric did not improve from 0.70149\n","Epoch 15/20\n","3196/3196 [==============================] - 246s 77ms/step - loss: 0.2716 - my_iou_metric: 0.6819 - val_loss: 0.3240 - val_my_iou_metric: 0.6858\n","\n","Epoch 00015: val_my_iou_metric did not improve from 0.70149\n","Epoch 16/20\n","3196/3196 [==============================] - 246s 77ms/step - loss: 0.2636 - my_iou_metric: 0.6998 - val_loss: 0.3614 - val_my_iou_metric: 0.6587\n","\n","Epoch 00016: val_my_iou_metric did not improve from 0.70149\n","\n","Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","Epoch 17/20\n","3196/3196 [==============================] - 246s 77ms/step - loss: 0.2057 - my_iou_metric: 0.7264 - val_loss: 0.3071 - val_my_iou_metric: 0.7127\n","\n","Epoch 00017: val_my_iou_metric improved from 0.70149 to 0.71269, saving model to unet_resnet.h5\n","Epoch 18/20\n","3196/3196 [==============================] - 247s 77ms/step - loss: 0.1828 - my_iou_metric: 0.7308 - val_loss: 0.3330 - val_my_iou_metric: 0.7024\n","\n","Epoch 00018: val_my_iou_metric did not improve from 0.71269\n","Epoch 19/20\n","3196/3196 [==============================] - 247s 77ms/step - loss: 0.1631 - my_iou_metric: 0.7416 - val_loss: 0.3285 - val_my_iou_metric: 0.7188\n","\n","Epoch 00019: val_my_iou_metric improved from 0.71269 to 0.71878, saving model to unet_resnet.h5\n","Epoch 20/20\n","3196/3196 [==============================] - 247s 77ms/step - loss: 0.1470 - my_iou_metric: 0.7564 - val_loss: 0.3749 - val_my_iou_metric: 0.6969\n","\n","Epoch 00020: val_my_iou_metric did not improve from 0.71878\n"],"name":"stdout"}]},{"metadata":{"id":"vyTSiTln28Di","colab_type":"text"},"cell_type":"markdown","source":["### Validation set prediction and resizing to original size:"]},{"metadata":{"id":"qDKBudR628Dj","colab_type":"code","colab":{}},"cell_type":"code","source":["val_preds = model_depth.predict(X_val, batch_size=16)\n","\n","y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n","y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1vYeTkKl28Dp","colab_type":"text"},"cell_type":"markdown","source":["### Threshold optimization: "]},{"metadata":{"id":"9ek8QZIn28D5","colab_type":"code","colab":{}},"cell_type":"code","source":["# src: https://www.kaggle.com/aglotero/another-iou-metric\n","def iou_metric(y_true_in, y_pred_in, print_table=False):\n","    labels = y_true_in\n","    y_pred = y_pred_in\n","    \n","    true_objects = 2\n","    pred_objects = 2\n","\n","    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n","\n","    # Compute areas (needed for finding the union between all objects)\n","    area_true = np.histogram(labels, bins = true_objects)[0]\n","    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n","    area_true = np.expand_dims(area_true, -1)\n","    area_pred = np.expand_dims(area_pred, 0)\n","\n","    # Compute union\n","    union = area_true + area_pred - intersection\n","\n","    # Exclude background from the analysis\n","    intersection = intersection[1:,1:]\n","    union = union[1:,1:]\n","    union[union == 0] = 1e-9\n","\n","    # Compute the intersection over union\n","    iou = intersection / union\n","\n","    # Precision helper function\n","    def precision_at(threshold, iou):\n","        matches = iou > threshold\n","        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n","        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n","        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n","        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n","        return tp, fp, fn\n","\n","    # Loop over IoU thresholds\n","    prec = []\n","    if print_table:\n","        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n","    for t in np.arange(0.5, 1.0, 0.05):\n","        tp, fp, fn = precision_at(t, iou)\n","        if (tp + fp + fn) > 0:\n","            p = tp / (tp + fp + fn)\n","        else:\n","            p = 0\n","        if print_table:\n","            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n","        prec.append(p)\n","    \n","    if print_table:\n","        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n","    return np.mean(prec)\n","\n","def iou_metric_batch(y_true_in, y_pred_in):\n","    batch_size = y_true_in.shape[0]\n","    metric = []\n","    for batch in range(batch_size):\n","        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n","        metric.append(value)\n","    return np.mean(metric)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"i_XuBy3n28D_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"446ab1c3-2311-444a-f5d7-d87658a0de61","executionInfo":{"status":"ok","timestamp":1553062049106,"user_tz":-540,"elapsed":57174,"user":{"displayName":"はぎ","photoUrl":"","userId":"03923874740366966476"}}},"cell_type":"code","source":["# Threshold range, over which optimization is performed\n","thresholds = np.arange(0.2, 0.9, 0.02)\n","\n","# For every threshold, set predictions to binary arrays, \n","# where values above threshold are treated as 1 and the rest as 0.\n","# Loop over thresholds and compute IoU for them based on IoU function above.\n","ious = np.array(\n","    [iou_metric_batch(y_val_true,\n","                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"],"execution_count":41,"outputs":[{"output_type":"stream","text":["100%|██████████| 35/35 [00:53<00:00,  1.51s/it]\n"],"name":"stderr"}]},{"metadata":{"id":"QurFoCXU28EJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":314},"outputId":"8e1cd82b-0788-4ef2-b7a1-175bc3bd1a33","executionInfo":{"status":"ok","timestamp":1553062049108,"user_tz":-540,"elapsed":55865,"user":{"displayName":"はぎ","photoUrl":"","userId":"03923874740366966476"}}},"cell_type":"code","source":["df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n","df_iou['iou'] = ious\n","\n","# Get index of best IoU\n","best_index = df_iou['iou'].idxmax()\n","print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n","    df_iou.iou[best_index], df_iou.threshold[best_index]))\n","\n","# Describe IoU DF\n","df_iou.describe()"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Best IoU: 0.7174 at threshold: 0.780\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>threshold</th>\n","      <th>iou</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>35.000000</td>\n","      <td>35.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.540000</td>\n","      <td>0.706031</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.204939</td>\n","      <td>0.013028</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.200000</td>\n","      <td>0.672637</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.370000</td>\n","      <td>0.698259</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.540000</td>\n","      <td>0.713433</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.710000</td>\n","      <td>0.715112</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.880000</td>\n","      <td>0.717413</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       threshold        iou\n","count  35.000000  35.000000\n","mean    0.540000   0.706031\n","std     0.204939   0.013028\n","min     0.200000   0.672637\n","25%     0.370000   0.698259\n","50%     0.540000   0.713433\n","75%     0.710000   0.715112\n","max     0.880000   0.717413"]},"metadata":{"tags":[]},"execution_count":42}]},{"metadata":{"id":"w18fPHwi28EO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":568},"outputId":"72ddf528-f918-4008-e2c9-c9354b766082","executionInfo":{"status":"ok","timestamp":1553062049109,"user_tz":-540,"elapsed":54421,"user":{"displayName":"はぎ","photoUrl":"","userId":"03923874740366966476"}}},"cell_type":"code","source":["# Plot IoU values over threshold range.\n","df_iou.plot(x='threshold', y='iou')"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f64c71bfef0>"]},"metadata":{"tags":[]},"execution_count":43},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAsYAAAIWCAYAAABUVkuaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJUmSJMBiLEmSJAEWY0mSJAmA/wNlw+bY1FKbfwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 864x648 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"1_-kAt5f28ES","colab_type":"text"},"cell_type":"markdown","source":["## Conclusions:\n","\n","- Pretrained models can be used for segmentation problems:\n","    - Some of architectures can be easily adapted to the problem (ie ResNet)\n","    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n","    - You can experiment with selection of layers for feature extraction\n","    - For some models, you can also try to experiment with number of encoder/decoder blocks\n","- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n","    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n","- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n","    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n","\n","\n","### Possible experiments:\n","\n","- Change type of decoder block in created segmentation model\n","- Create your own decoder blocks\n","- Train with other losses\n","- Train longer\n","- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n","- Try different ranges and intervals for threshold optimization"]},{"metadata":{"id":"MCJaAQVs28ET","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}