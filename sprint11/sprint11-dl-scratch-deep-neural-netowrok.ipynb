{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ディープラーニングをスクラッチする課題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】全結合層のクラス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "        self.Z = 0\n",
    "        self.dA = 0\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        self.Z = deepcopy(X)\n",
    "        A = np.dot(X, self.W) + self.B\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        self.dA = deepcopy(dA)\n",
    "        dW = np.dot(self.Z.T, dA)\n",
    "        dZ = np.dot(dA, self.W.T) \n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】初期化方法のクラス化\n",
    "# 【問題6】重みの初期値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "code_folding": [
     0,
     44,
     86
    ]
   },
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sigma=0.01):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W : 次の形のndarray, shape(n_nodes1, n_nodes2)\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W.astype(\"f\")\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : 次の形のndarray, shape(1, nodes2)\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B.astype(\"f\")\n",
    "    \n",
    "class XavierInitializer:\n",
    "    \"\"\"\n",
    "    Xavierによる初期化\n",
    "    Sigmoid」かTanhに向いている\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sigma = None\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W : 次の形のndarray, shape(n_nodes1, n_nodes2)\n",
    "        \"\"\"\n",
    "        self.sigma = 1 / np.sqrt(n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W.astype(\"f\")\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : 次の形のndarray, shape(1, nodes2)\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B.astype(\"f\")\n",
    "    \n",
    "class HeInitializer:\n",
    "    \"\"\"\n",
    "    Heによる初期化\n",
    "    ReLUと相性がいい\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sigma = 0\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W : 次の形のndarray, shape(n_nodes1, n_nodes2)\n",
    "        \"\"\"\n",
    "        self.sigma = np.sqrt(2 / n_nodes1)\n",
    "        W = (self.sigma * np.random.randn(n_nodes1, n_nodes2))\n",
    "        return W.astype(\"f\")\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : 次の形のndarray, shape(1, nodes2)\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B.astype(\"f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】最適化手法のクラス化\n",
    " # 【問題7】最適化手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "code_folding": [
     0,
     25,
     57,
     95
    ]
   },
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "        layer.W[...] = layer.W - self.lr * np.dot(layer.Z.T, layer.dA) / len(layer.dA)\n",
    "        layer.B[...] = layer.B - self.lr * np.mean(layer.dA, axis=0)\n",
    "        return layer\n",
    "\n",
    "class AdaGrad:\n",
    "    \"\"\"\n",
    "    学習率を変化を減少させていく勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.HW = 0\n",
    "        self.HB = 0\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "        \n",
    "        dW = np.dot(layer.Z.T, layer.dA) / len(layer.dA)\n",
    "        dB = np.mean(layer.dA, axis=0)\n",
    "        self.HW += dW**2\n",
    "        self.HB +=  dB**2\n",
    "        layer.W[...] = layer.W - self.lr / np.sqrt(self.HW +1e-7) * dW #0で割るとまずいので +le-7\n",
    "        layer.B[...] = layer.B - self.lr / np.sqrt(self.HB + 1e-7)  * dB\n",
    "        return layer\n",
    "    \n",
    "class Momentum:\n",
    "    \n",
    "    \"\"\"\n",
    "    momentumSGD\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    momentum : 学習係数\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.vW = 0\n",
    "        self.vB = 0\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "\n",
    "        dW = np.dot(layer.Z.T, layer.dA) / len(layer.dA)\n",
    "        dB = np.mean(layer.dA, axis=0)\n",
    "        \n",
    "        self.vW = self.momentum * self.vW - self.lr * dW\n",
    "        self.vB =  self.momentum * self.vB - self.lr * dB\n",
    "        \n",
    "        layer.W[...] = layer.W + self.vW\n",
    "        layer.B[...] = layer.B + self.vB\n",
    "        \n",
    "        return layer\n",
    "    \n",
    "class Adam:\n",
    "\n",
    "    \"\"\"\n",
    "    Adam\n",
    "    RMSprop に Momentum 法を組み合わせたような形\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    momentum : 学習係数\n",
    "    beta1\n",
    "    beta2\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iter = 0\n",
    "        self.mW = 0\n",
    "        self.vW = 0\n",
    "        self.mB = 0\n",
    "        self.vB = 0\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \n",
    "        self.iter += 1\n",
    "        dW = np.dot(layer.Z.T, layer.dA) / len(layer.dA)\n",
    "        dB = np.mean(layer.dA, axis=0)\n",
    "        \n",
    "        lr_t  = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter) \n",
    "        \n",
    "        self.mW += (1 - self.beta1) * (dW - self.mW)\n",
    "        self.vW += (1 - self.beta2) * (dW**2 - self.vW)\n",
    "        self.mB += (1 - self.beta1) * (dB - self.mB)\n",
    "        self.vB += (1 - self.beta2) * (dB**2 - self.vB)\n",
    "        \n",
    "        layer.W -= lr_t * self.mW / (np.sqrt(self.vW) + 1e-7)\n",
    "        layer.B -= lr_t * self.mB / (np.sqrt(self.vB) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】活性化関数のクラス化\n",
    "# 【問題5】ReLUクラスの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "code_folding": [
     0,
     39,
     78,
     123
    ]
   },
   "outputs": [],
   "source": [
    "class sigmoid:\n",
    "    \"\"\"\n",
    "    シグモイド関数\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.Z = 0\n",
    "    \n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        Z = 1 / (1 + np.exp(-A))\n",
    "        self.Z = Z\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        dA = dZ  *  (1 - self.Z) * self.Z \n",
    "        return dA\n",
    "    \n",
    "class Tanh:\n",
    "    \"\"\"\n",
    "    ハイパボリックタンジェント関数\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.Z = 0\n",
    "    \n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        Z = np.tanh(A)\n",
    "        self.Z = Z\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        dA = dZ  *  (1 - self.Z**2)\n",
    "        return dA\n",
    "\n",
    "class Softmax:\n",
    "    \"\"\"\n",
    "    ソフトマックス関数\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.Z = 0\n",
    "    \n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        \n",
    "        c = np.max(A)\n",
    "        A = A - c\n",
    "        ex = np.exp(A)\n",
    "        Z = ex / (np.sum(ex, axis=1))[:, np.newaxis]\n",
    "        self.Z = Z\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, y):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : 次の形のndarray, shape (batch_size, n_class)\n",
    "            正解ラベル\n",
    "        Returns\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_class)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        \n",
    "        dA = self.Z - y\n",
    "        \n",
    "        return dA\n",
    "    \n",
    "class ReLU:\n",
    "    \"\"\"\n",
    "    ReLU関数\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.Z = None\n",
    "    \n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        Z = np.maximum(0, A)\n",
    "        self.Z = deepcopy(Z)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        \n",
    "        dA = dZ  *  np.where(self.Z != 0, 1, self.Z)\n",
    "        \n",
    "        return dA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self.X = X[shuffle_index]\n",
    "        self.y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    \n",
    "    #Pythonの特殊メソッドのひとつで、オブジェクトに角括弧でアクセスしたときの挙動を定義できる。\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self.X[p0:p1], self.y[p0:p1]        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self.X[p0:p1], self.y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "code_folding": [
     6
    ]
   },
   "outputs": [],
   "source": [
    "#これは使ってません\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class ScratchDeepNeuralNetrowkClassifier:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_nodes1, n_nodes2, n_output, sigma=0.01, lr=0.01, batch_size=50, epoch=10, verbose=True, metrics=\"acc\"):\n",
    "        self.sigma = sigma\n",
    "        self.lr = lr\n",
    "        self.n_features = 0\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.n_output = n_output\n",
    "        self.batch_size = batch_size\n",
    "        self.epoch = epoch\n",
    "        self.metrics = metrics\n",
    "        self.verbose = verbose\n",
    "        self.train_loss = np.zeros(epoch)\n",
    "        self.val_loss = np.zeros(epoch)\n",
    "        self.layers = []\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            学習用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "        \n",
    "        # self.sigma : ガウス分布の標準偏差\n",
    "        # self.lr : 学習率\n",
    "        # self.n_nodes1 : 1層目のノード数\n",
    "        # self.n_nodes2 : 2層目のノード数\n",
    "        # self.n_output : 出力層のノード数\n",
    "        self.n_features = X.shape[1]\n",
    "\n",
    "        optimizer = SGD(self.lr)\n",
    "        #optimizer = AdaGrad(self.lr)\n",
    "        #Initializer = SimpleInitializer()\n",
    "        Initializer = HeInitializer()\n",
    "        \n",
    "        FC1 = FC(self.n_features, self.n_nodes1, Initializer, optimizer)\n",
    "        activation1 = ReLU()\n",
    "        FC2 = FC(self.n_nodes1, self.n_nodes2, Initializer, optimizer)\n",
    "        activation2 = ReLU()\n",
    "        FC3 = FC(self.n_nodes2, self.n_output, Initializer, optimizer)\n",
    "        activation3 = Softmax()\n",
    "        \n",
    "        self.construction(FC1)\n",
    "        self.construction(activation1)\n",
    "        self.construction(FC2)\n",
    "        self.construction(activation2)\n",
    "        self.construction(FC3)\n",
    "        self.construction(activation3)\n",
    "        \n",
    "        #self.construction(FC(self.n_features, self.n_nodes1, Initializer, optimizer))\n",
    "        #self.construction(ReLU())\n",
    "        #self.construction(b)\n",
    "        #self.construction(FC(self.n_nodes1, self.n_nodes2, Initializer, optimizer))\n",
    "        #self.construction(ReLU())\n",
    "        #self.construction(FC(self.n_nodes2, self.n_output, Initializer, optimizer))\n",
    "        #self.construction(Softmax())\n",
    "        \n",
    "        for i in range(self.epoch):\n",
    "\n",
    "            #バッチ作成\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=56)\n",
    "\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                \n",
    "                #FP\n",
    "                self.FP(mini_X_train)\n",
    "\n",
    "                #BP\n",
    "                self.BP(mini_y_train)\n",
    "                \n",
    "            #評価値の表示\n",
    "            train_pred = self.FP(X)\n",
    "            self.train_loss[i] = self._cross_entropy_loss(train_pred, y)\n",
    "            \n",
    "            if np.any(X_val):\n",
    "                val_pred = self.FP(X_val)\n",
    "                self.val_loss[i] = self._cross_entropy_loss(val_pred, y_val)\n",
    "                met = self.accuracy(np.argmax(y_val, axis=1), np.argmax(val_pred, axis=1))\n",
    "                      \n",
    "                if self.verbose:\n",
    "                    print(\"epoch:{0} train_loss: {1} val_loss: {2} {3}: {4}\".format(i+1, self.train_loss[i], self.val_loss[i], self.metrics, met))\n",
    "                    \n",
    "            else:\n",
    "                if self.verbose:\n",
    "                      print(\"epoch:{0} loss: {1}\".format(i+1, self.train_loss[i]))\n",
    "     \n",
    "    def construction(self, layer):\n",
    "        self.layers += [layer]\n",
    "        \n",
    "    def FP(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "            \n",
    "        return X\n",
    "            \n",
    "    def BP(self, y):\n",
    "        for layer in reversed(self.layers):\n",
    "            y = layer.backward(y)\n",
    "            \n",
    "    def _cross_entropy_loss(self,z, y):\n",
    "        z += 0.00000001\n",
    "        return - sum(sum(y * np.log(z))) / len(y)\n",
    "    \n",
    "    def accuracy(self, y, y_pred):\n",
    "        # accuracyを計算して返す\n",
    "        return accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class ScratchDeepNeuralNetrowkClassifier2:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_features, batch_size=50, epoch=10, verbose=True, metrics=\"acc\"):\n",
    "        self.n_nodes = [n_features]\n",
    "        self.n_output = n_output\n",
    "        self.batch_size = batch_size\n",
    "        self.epoch = epoch\n",
    "        self.metrics = metrics\n",
    "        self.verbose = verbose\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        self.layers = []\n",
    "\n",
    "    \n",
    "    def add(self, layer_type, n_nodes=None, Initializer=None, optimizer=None):\n",
    "        \n",
    "        if layer_type == \"FC\":\n",
    "            self.layers += [FC(self.n_nodes[-1], n_nodes, Initializer, optimizer)]\n",
    "            self.n_nodes += [n_nodes]\n",
    "            \n",
    "        elif layer_type == \"ReLU\":\n",
    "            self.layers += [ReLU()]\n",
    "        \n",
    "        elif layer_type == \"Tanh\":\n",
    "            self.layers += [Tanh()]\n",
    "        \n",
    "        elif layer_type == \"sigmoid\":\n",
    "            self.layers += [sigmoid()]\n",
    "            \n",
    "        elif layer_type == \"Softmax\":\n",
    "            self.layers += [Softmax()]\n",
    "        else:\n",
    "            print(\"layer_typeが存在しません\")\n",
    "            \n",
    "    def fit(self, X, y, X_val=None, y_val=None, epoch=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            学習用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        epoch : int\n",
    "            エポック数変えたいときは入れてください\n",
    "        \"\"\"\n",
    "        if epoch:\n",
    "            self.epoch = epoch\n",
    "        \n",
    "        for i in range(self.epoch):\n",
    "\n",
    "            #バッチ作成\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=56)\n",
    "\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                \n",
    "                #FP\n",
    "                self.FP(mini_X_train)\n",
    "\n",
    "                #BP\n",
    "                self.BP(mini_y_train)\n",
    "                \n",
    "            #評価値等の表示\n",
    "            train_pred = self.FP(X)\n",
    "            self.train_loss += [self._cross_entropy_loss(train_pred, y)]\n",
    "            \n",
    "            if np.any(X_val):\n",
    "                val_pred = self.FP(X_val)\n",
    "                self.val_loss += [self._cross_entropy_loss(val_pred, y_val)]\n",
    "                \n",
    "                #metricsを判定\n",
    "                if  self.metrics == \"acc\":\n",
    "                    met = self.accuracy(np.argmax(y_val, axis=1), np.argmax(val_pred, axis=1))\n",
    "                else:\n",
    "                    print(\"metricsの入力が間違っています\")\n",
    "                      \n",
    "                if self.verbose:\n",
    "                    print(\"epoch:{0} train_loss: {1} val_loss: {2} {3}: {4}\".format(i+1, self.train_loss[i], self.val_loss[i], self.metrics, met))\n",
    "                    \n",
    "            else:\n",
    "                if self.verbose:\n",
    "                      print(\"epoch:{0} loss: {1}\".format(i+1, self.train_loss[i]))\n",
    "     \n",
    "    def FP(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "            \n",
    "        return X\n",
    "            \n",
    "    def BP(self, y):\n",
    "        for layer in reversed(self.layers):\n",
    "            y = layer.backward(y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        hx = self.FP(X)\n",
    "        return np.argmax(hx, axis=1)\n",
    "            \n",
    "    def _cross_entropy_loss(self,z, y):\n",
    "        z += 1e-7\n",
    "        return - sum(sum(y * np.log(z))) / len(y)\n",
    "    \n",
    "    def accuracy(self, y, y_pred):\n",
    "        # accuracyを計算して返す\n",
    "        return accuracy_score(y, y_pred)\n",
    "    \n",
    "    def plot_learning_curve(self):\n",
    "        \"\"\"\n",
    "        学習曲線をプロットします。\n",
    "\n",
    "        loss : array\n",
    "        一回ごとの勾配降下方のロスのログ(train)\n",
    "         val_los : array\n",
    "        一回ごとの勾配降下方のロスのログ(val or test)\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.title(\"model_loss\")\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.plot(self.train_loss, label=\"train_loss\")\n",
    "        plt.plot(self.val_loss, label=\"val_loss\")\n",
    "        #plt.yscale(\"log\")\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#データのロード\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "#フラットにする\n",
    "X_train = x_train.reshape(-1, 784)\n",
    "X_test = x_test.reshape(-1, 784)\n",
    "#スケール合わせ\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "#onehot\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "#sprit train and val\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_train.shape[1]\n",
    "model2 = ScratchDeepNeuralNetrowkClassifier2(n_features=n, batch_size=50, epoch=80, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = SGD(0.01)\n",
    "#optimizer1 = AdaGrad(0.01)\n",
    "#Initializer = SimpleInitializer()\n",
    "#Initializer = HeInitializer()\n",
    "#XavierInitializer\n",
    "#Momentum\n",
    "#Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.add(\"FC\", 400, XavierInitializer(), Momentum(0.01, 0.9))\n",
    "model2.add(\"Tanh\")\n",
    "model2.add(\"FC\", 400, XavierInitializer(), Momentum(0.01, 0.9))\n",
    "model2.add(\"Tanh\")\n",
    "model2.add(\"FC\", 400, XavierInitializer(), Momentum(0.01, 0.9))\n",
    "model2.add(\"Tanh\")\n",
    "model2.add(\"FC\", 200, XavierInitializer(), Momentum(0.01, 0.9))\n",
    "model2.add(\"Tanh\")\n",
    "model2.add(\"FC\", 200, XavierInitializer(), Momentum(0.01, 0.9))\n",
    "model2.add(\"Tanh\")\n",
    "model2.add(\"FC\", 100, XavierInitializer(), Momentum(0.01, 0.9))\n",
    "model2.add(\"Tanh\")\n",
    "model2.add(\"FC\", 100, XavierInitializer(), Momentum(0.01, 0.9))\n",
    "model2.add(\"Tanh\")\n",
    "model2.add(\"FC\", 10, XavierInitializer(), Momentum(0.01, 0.9))\n",
    "model2.add(\"Softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.FC at 0x1a3d026cf8>,\n",
       " <__main__.Tanh at 0x1a44424470>,\n",
       " <__main__.FC at 0x1a3d0268d0>,\n",
       " <__main__.Tanh at 0x1a3d026e48>,\n",
       " <__main__.FC at 0x1a3ededef0>,\n",
       " <__main__.Tanh at 0x1a3d026a20>,\n",
       " <__main__.FC at 0x1a43313f98>,\n",
       " <__main__.Tanh at 0x1a3eded9e8>,\n",
       " <__main__.FC at 0x1a43313e10>,\n",
       " <__main__.Tanh at 0x1a43313400>,\n",
       " <__main__.FC at 0x1a3bf4cef0>,\n",
       " <__main__.Tanh at 0x1a43313a20>,\n",
       " <__main__.FC at 0x1a3bf4c748>,\n",
       " <__main__.Tanh at 0x1a3bf4c470>,\n",
       " <__main__.FC at 0x1a3bf4c668>,\n",
       " <__main__.Softmax at 0x1a3bf4cf60>]"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 train_loss: 0.20406753222147625 val_loss: 0.22625635457227922 acc: 0.9301666666666667\n",
      "epoch:2 train_loss: 0.13403254699707032 val_loss: 0.16297755913294795 acc: 0.95225\n",
      "epoch:3 train_loss: 0.08944449551900228 val_loss: 0.12396296458292101 acc: 0.9640833333333333\n",
      "epoch:4 train_loss: 0.07124495728810629 val_loss: 0.11224698432382942 acc: 0.9673333333333334\n",
      "epoch:5 train_loss: 0.06567094167073567 val_loss: 0.11337616302820362 acc: 0.9681666666666666\n",
      "epoch:6 train_loss: 0.04723383665084839 val_loss: 0.09969378736409207 acc: 0.9716666666666667\n",
      "epoch:7 train_loss: 0.04317154471079508 val_loss: 0.10013958400554249 acc: 0.97175\n",
      "epoch:8 train_loss: 0.04041378633181254 val_loss: 0.10251083751366463 acc: 0.9718333333333333\n",
      "epoch:9 train_loss: 0.03125425553321838 val_loss: 0.10056137846035078 acc: 0.9734166666666667\n",
      "epoch:10 train_loss: 0.023156980593999225 val_loss: 0.09465511646492282 acc: 0.9759166666666667\n",
      "epoch:11 train_loss: 0.017184126496315004 val_loss: 0.09519316954745492 acc: 0.9756666666666667\n",
      "epoch:12 train_loss: 0.012797170042991638 val_loss: 0.09566807078106973 acc: 0.976\n",
      "epoch:13 train_loss: 0.019271175583203633 val_loss: 0.10094088014284897 acc: 0.9740833333333333\n",
      "epoch:14 train_loss: 0.01351869793732961 val_loss: 0.09863283297663376 acc: 0.9764166666666667\n",
      "epoch:15 train_loss: 0.009786605924367905 val_loss: 0.10087363764903617 acc: 0.9761666666666666\n",
      "epoch:16 train_loss: 0.010557283083597819 val_loss: 0.1070235496806284 acc: 0.97525\n",
      "epoch:17 train_loss: 0.00767886479695638 val_loss: 0.10176793412053614 acc: 0.9766666666666667\n",
      "epoch:18 train_loss: 0.010390363017717997 val_loss: 0.10833723951787395 acc: 0.9759166666666667\n",
      "epoch:19 train_loss: 0.004827556312084198 val_loss: 0.10243857102648261 acc: 0.9764166666666667\n",
      "epoch:20 train_loss: 0.003201223502556483 val_loss: 0.0960196456565972 acc: 0.9781666666666666\n",
      "epoch:21 train_loss: 0.004872741803526879 val_loss: 0.10713772091685962 acc: 0.9773333333333334\n",
      "epoch:22 train_loss: 0.0024396592353781066 val_loss: 0.09690790367733906 acc: 0.979\n",
      "epoch:23 train_loss: 0.0009631371075908343 val_loss: 0.09642787236529692 acc: 0.9796666666666667\n",
      "epoch:24 train_loss: 0.00040561407804489135 val_loss: 0.0937221825688083 acc: 0.9806666666666667\n",
      "epoch:25 train_loss: 0.0002962585985660553 val_loss: 0.09322909757186078 acc: 0.981\n",
      "epoch:26 train_loss: 0.0002462796395023664 val_loss: 0.09329138849716506 acc: 0.9805833333333334\n",
      "epoch:27 train_loss: 0.00021768471598625184 val_loss: 0.09346519219236529 acc: 0.9805\n",
      "epoch:28 train_loss: 0.00019675088052948316 val_loss: 0.09368360978817562 acc: 0.9805833333333334\n",
      "epoch:29 train_loss: 0.00018031189714868865 val_loss: 0.09390892019587545 acc: 0.98075\n",
      "epoch:30 train_loss: 0.00016687803094585736 val_loss: 0.09413186790949428 acc: 0.9808333333333333\n",
      "epoch:31 train_loss: 0.0001556010904411475 val_loss: 0.09434929730077372 acc: 0.9810833333333333\n",
      "epoch:32 train_loss: 0.00014594658588369688 val_loss: 0.09456005906372261 acc: 0.98125\n",
      "epoch:33 train_loss: 0.00013755353912711145 val_loss: 0.09476384476785643 acc: 0.9813333333333333\n",
      "epoch:34 train_loss: 0.00013016809274752936 val_loss: 0.09496075220688395 acc: 0.9813333333333333\n",
      "epoch:35 train_loss: 0.00012360325207312901 val_loss: 0.09515100785262048 acc: 0.9813333333333333\n",
      "epoch:36 train_loss: 0.00011771945717434088 val_loss: 0.09533492014597465 acc: 0.98125\n",
      "epoch:37 train_loss: 0.00011240702743331591 val_loss: 0.09551281654387571 acc: 0.98125\n",
      "epoch:38 train_loss: 0.00010758208483457566 val_loss: 0.09568506888358011 acc: 0.98125\n",
      "epoch:39 train_loss: 0.00010317572702964147 val_loss: 0.09585195046630711 acc: 0.98125\n",
      "epoch:40 train_loss: 9.913214792807896e-05 val_loss: 0.09601380952083205 acc: 0.98125\n",
      "epoch:41 train_loss: 9.540713826815287e-05 val_loss: 0.09617092091177822 acc: 0.9811666666666666\n",
      "epoch:42 train_loss: 9.196156946321329e-05 val_loss: 0.09632356679846593 acc: 0.9813333333333333\n",
      "epoch:43 train_loss: 8.87640913327535e-05 val_loss: 0.09647200433562411 acc: 0.9813333333333333\n",
      "epoch:44 train_loss: 8.57878935833772e-05 val_loss: 0.0966164545419313 acc: 0.9813333333333333\n",
      "epoch:45 train_loss: 8.300888352096081e-05 val_loss: 0.0967571406904064 acc: 0.9813333333333333\n",
      "epoch:46 train_loss: 8.040840240816275e-05 val_loss: 0.09689422777585542 acc: 0.9813333333333333\n",
      "epoch:47 train_loss: 7.796873586873213e-05 val_loss: 0.09702796787427677 acc: 0.9813333333333333\n",
      "epoch:48 train_loss: 7.567548876007398e-05 val_loss: 0.09715850466641487 acc: 0.98125\n",
      "epoch:49 train_loss: 7.351469931503137e-05 val_loss: 0.09728596048663163 acc: 0.98125\n",
      "epoch:50 train_loss: 7.147540214161079e-05 val_loss: 0.09741052408034792 acc: 0.9813333333333333\n",
      "epoch:51 train_loss: 6.954703728357951e-05 val_loss: 0.09753233101137533 acc: 0.9813333333333333\n",
      "epoch:52 train_loss: 6.772050571938356e-05 val_loss: 0.09765150296117169 acc: 0.9814166666666667\n",
      "epoch:53 train_loss: 6.598805698255698e-05 val_loss: 0.0977681409009606 acc: 0.9814166666666667\n",
      "epoch:54 train_loss: 6.434255310644707e-05 val_loss: 0.09788235779503679 acc: 0.9813333333333333\n",
      "epoch:55 train_loss: 6.277722585946321e-05 val_loss: 0.0979942678870159 acc: 0.9813333333333333\n",
      "epoch:56 train_loss: 6.128575342396895e-05 val_loss: 0.09810397475205836 acc: 0.9814166666666667\n",
      "epoch:57 train_loss: 5.9863798630734284e-05 val_loss: 0.09821155800951602 acc: 0.9814166666666667\n",
      "epoch:58 train_loss: 5.8505923487246034e-05 val_loss: 0.09831709905339434 acc: 0.9814166666666667\n",
      "epoch:59 train_loss: 5.720824158440034e-05 val_loss: 0.09842070847249952 acc: 0.9814166666666667\n",
      "epoch:60 train_loss: 5.596688607086738e-05 val_loss: 0.09852240948153415 acc: 0.9815\n",
      "epoch:61 train_loss: 5.4777652025222775e-05 val_loss: 0.09862233920019269 acc: 0.9815\n",
      "epoch:62 train_loss: 5.363741423934698e-05 val_loss: 0.09872049884297002 acc: 0.9814166666666667\n",
      "epoch:63 train_loss: 5.254365845272938e-05 val_loss: 0.09881700640985625 acc: 0.9814166666666667\n",
      "epoch:64 train_loss: 5.1492835395038127e-05 val_loss: 0.09891190346029151 acc: 0.9814166666666667\n",
      "epoch:65 train_loss: 5.048305044571559e-05 val_loss: 0.09900521627894687 acc: 0.9815\n",
      "epoch:66 train_loss: 4.951176544030507e-05 val_loss: 0.0990970529936684 acc: 0.9815\n",
      "epoch:67 train_loss: 4.857646332432826e-05 val_loss: 0.09918740660998465 acc: 0.9815\n",
      "epoch:68 train_loss: 4.767574400951465e-05 val_loss: 0.09927637116220617 acc: 0.9815\n",
      "epoch:69 train_loss: 4.680744372308254e-05 val_loss: 0.0993639663685751 acc: 0.9815\n",
      "epoch:70 train_loss: 4.5969302455584205e-05 val_loss: 0.09945024691440767 acc: 0.9815\n",
      "epoch:71 train_loss: 4.516065275917451e-05 val_loss: 0.09953526117433428 acc: 0.9815\n",
      "epoch:72 train_loss: 4.437932372093201e-05 val_loss: 0.09961904415908557 acc: 0.9815\n",
      "epoch:73 train_loss: 4.3624213896691796e-05 val_loss: 0.09970162306510238 acc: 0.9815\n",
      "epoch:74 train_loss: 4.289384527752797e-05 val_loss: 0.09978302739257831 acc: 0.9815\n",
      "epoch:75 train_loss: 4.2187370049456756e-05 val_loss: 0.09986332030932875 acc: 0.9815\n",
      "epoch:76 train_loss: 4.150338812420766e-05 val_loss: 0.09994250298982452 acc: 0.9815\n",
      "epoch:77 train_loss: 4.0840964764356615e-05 val_loss: 0.10002062540052035 acc: 0.9815\n",
      "epoch:78 train_loss: 4.01985024412473e-05 val_loss: 0.1000977204723221 acc: 0.9815\n",
      "epoch:79 train_loss: 3.9575861456493535e-05 val_loss: 0.10017380650596568 acc: 0.9815\n",
      "epoch:80 train_loss: 3.897168766707182e-05 val_loss: 0.10024892819642359 acc: 0.9815\n"
     ]
    }
   ],
   "source": [
    "model2.fit(X_train.astype(\"f\"), y_train.astype(\"f\"), X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAFNCAYAAAAHGMa6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl4VOXd//H3N5nJRkgCYScgi6DsoAHBhbpVcd8VFRXrUqu1aqtV26fVUu3PPm1ta7VS17pVxa2lrnX3cUMCIoLsFCTs+5Y9uX9/nJMwCVkmy2Qyk8/ruubKnDP3mfkeSPLJfZb7NuccIiIiEr8Sol2AiIiIRJbCXkREJM4p7EVEROKcwl5ERCTOKexFRETinMJeREQkzinsRURE4pzCXkRqZWZ/N7O7wmy7ysyOb6DNnWb2dMtUJyKNobAXERGJcwp7ERGROKewF4lx/iH0W8xsvpntNbNHzay7mb1hZrvN7B0z6+S3Pd3MFprZDjP7wMyGhLzPGDOb62/zPJBS43NONbN5/rafmtnIZtZdXy23mtlav5YlZnacv36cmeWZ2S4z22hm9zanBpH2QmEvEh/OAb4LDAZOA94AfgZ0wfs5/5GZDQaeBW4EugKvA/82syQzSwL+CTwFdAZe8N8TADM7BHgM+D6QDfwNmGlmyU0ptoFaDgJ+CIx1znUETgRW+Zv+Gfizcy4DGAjMaMrni7Q3CnuR+PAX59xG59xa4P+AWc65L51zxcArwBjgAuA159zbzrlS4PdAKnA4MB4IAn9yzpU6514EZoe8/1XA35xzs5xz5c65J4Bif7umqK+WciAZGGpmQefcKufcCn+7UuBAM+vinNvjnPu8iZ8v0q4o7EXiw8aQ54W1LKcDvYDVlSudcxXAGqC3/9paV30azNUhzw8AfuIfct9hZjuAPv52TVFnLc655Xg9/juBTWb2nJlVfs4VeEcvFpvZbDM7tYmfL9KuKOxF2o91eKENgJkZXmCvBdYDvf11lfqGPF8D3O2cywp5pDnnno1ALTjn/uGcO9Jv44Df+uuXOecuBLr56140sw5NrEGk3VDYi7QfM4BTzOw4MwsCP8E7FP8p8BlQhnduP2BmZwPjQrZ9GLjGzA4zTwczO8XMOrZ0LWZ2kJkd618PUIR3ZKIcwMymmFlX/0jADv+9yptYg0i7obAXaSecc0uAKcBfgC14F/Kd5pwrcc6VAGcDU4HteOfUXw7ZNg/vvP39/uvL/bYtXgve+fp7/PUb8HrxP/M3nQQsNLM9eBfrTXbOFTW1DpH2wqqfohMREZF4o569iIhInFPYi0iL8Qfy2VPL42cNby0ikaLD+CIiInFOPXsREZE4F4h2AS2lS5curl+/ftEuQ0REpNXMmTNni3Oua0Pt4ibs+/XrR15eXrTLEBERaTVmtrrhVjqMLyIiEvcU9iIiInFOYS8iIhLn4uacvYiItC2lpaXk5+dTVKQRjZsrJSWFnJwcgsFgk7ZX2IuISETk5+fTsWNH+vXrR/UJFaUxnHNs3bqV/Px8+vfv36T30GF8ERGJiKKiIrKzsxX0zWRmZGdnN+sIicJeREQiRkHfMpr776iwFxERiXMKexERiUs7duzgr3/9a6O3O/nkk9mxY0ejt5s6dSovvvhio7drDQr72pSXwtynYN28aFciIiJNVFfYl5eX17vd66+/TlZWVqTKigqFfW0sAWZeD0tej3YlIiLSRLfddhsrVqxg9OjRjB07lmOOOYaLLrqIESNGAHDmmWdy6KGHMmzYMB566KGq7fr168eWLVtYtWoVQ4YM4aqrrmLYsGGccMIJFBYWhvXZ7777LmPGjGHEiBF873vfo7i4uKqmoUOHMnLkSG6++WYAXnjhBYYPH86oUaOYOHFiC/8reHTrXW0SEiElEwq2RbsSEZG48Kt/L+Sbdbta9D2H9srgjtOG1fn6Pffcw4IFC5g3bx4ffPABp5xyCgsWLKi6fe2xxx6jc+fOFBYWMnbsWM455xyys7OrvceyZct49tlnefjhhzn//PN56aWXmDJlSr11FRUVMXXqVN59910GDx7MpZdeyoMPPsill17KK6+8wuLFizGzqlMF06ZN46233qJ3795NOn0QDvXs65LWGQoV9iIi8WLcuHHV7lO/7777GDVqFOPHj2fNmjUsW7Zsv2369+/P6NGjATj00ENZtWpVg5+zZMkS+vfvz+DBgwG47LLL+Oijj8jIyCAlJYUrr7ySl19+mbS0NACOOOIIpk6dysMPP9zgKYamUs++Lqmd1bMXEWkh9fXAW0uHDh2qnn/wwQe88847fPbZZ6SlpXH00UfXeh97cnJy1fPExMSwDuM752pdHwgE+OKLL3j33Xd57rnnuP/++3nvvfeYPn06s2bN4rXXXmP06NHMmzdvvyMMzaWwr0taZ9izMdpViIhIE3Xs2JHdu3fX+trOnTvp1KkTaWlpLF68mM8//7zFPvfggw9m1apVLF++nAMPPJCnnnqK73znO+zZs4eCggJOPvlkxo8fz4EHHgjAihUrOOywwzjssMP497//zZo1axT2rSa1M2xaHO0qRESkibKzszniiCMYPnw4qampdO/eveq1SZMmMX36dEaOHMlBBx3E+PHjW+xzU1JSePzxxznvvPMoKytj7NixXHPNNWzbto0zzjiDoqIinHP88Y9/BOCWW25h2bJlOOc47rjjGDVqVIvVUsnqOtwQa3Jzc11eXl7LveGbt8PcJ+Fna1vuPUVE2pFFixYxZMiQaJcRN2r79zSzOc653Ia21QV6dUntDCV7oKwk2pWIiIg0iw7j1yWtk/e1cBt07BHdWkREpM247rrr+OSTT6qtu+GGG7j88sujVFHDFPZ1Se3sfS1Q2IuIyD4PPPBAtEtoNB3Gr0uaH/a6115ERGKcwr4uoT17ERGRGKawr4t69iIiEicU9nVRz15EROKEwr4uSWkQSFHPXkSknUhPT6/ztVWrVjF8+PBWrKZlKezrk9oZCrZHuwoREZFm0a139dHMdyIiLeON22DD1y37nj1GwEn31PnyrbfeygEHHMC1114LwJ133omZ8dFHH7F9+3ZKS0u56667OOOMMxr1sUVFRfzgBz8gLy+PQCDAvffeyzHHHMPChQu5/PLLKSkpoaKigpdeeolevXpx/vnnk5+fT3l5Ob/4xS+44IILmrXbTaGwr09qJyjYGu0qRESkCSZPnsyNN95YFfYzZszgzTff5KabbiIjI4MtW7Ywfvx4Tj/9dMws7PetvM/+66+/ZvHixZxwwgksXbqU6dOnc8MNN3DxxRdTUlJCeXk5r7/+Or169eK1114DvAl4okFhX5+0bNi4MNpViIjEvnp64JEyZswYNm3axLp169i8eTOdOnWiZ8+e3HTTTXz00UckJCSwdu1aNm7cSI8e4Q+e9vHHH3P99dcD3gx3BxxwAEuXLmXChAncfffd5Ofnc/bZZzNo0CBGjBjBzTffzK233sqpp57KUUcdFandrZfO2ddHh/FFRGLaueeey4svvsjzzz/P5MmTeeaZZ9i8eTNz5sxh3rx5dO/evdZ57OtT1wRyF110ETNnziQ1NZUTTzyR9957j8GDBzNnzhxGjBjB7bffzrRp01pitxpNPfv6pHaGwu1QUQEJ+rtIRCTWTJ48mauuuootW7bw4YcfMmPGDLp160YwGOT9999n9erVjX7PiRMn8swzz3DssceydOlSvv32Ww466CBWrlzJgAED+NGPfsTKlSuZP38+Bx98MJ07d2bKlCmkp6fz97//veV3MgwK+/qkdQZXAcU7vfP3IiISU4YNG8bu3bvp3bs3PXv25OKLL+a0004jNzeX0aNHc/DBBzf6Pa+99lquueYaRowYQSAQ4O9//zvJyck8//zzPP300wSDQXr06MEvf/lLZs+ezS233EJCQgLBYJAHH3wwAnvZMM1nX595z8I/r4Hr50L2wJZ9bxGROKf57FuW5rNvYRUVjpWb97DTOnorCnWvvYiIxC4dxq9FWYXj2D98yP8eVsL5oCFzRUTaia+//ppLLrmk2rrk5GRmzZoVpYpaRkTD3swmAX8GEoFHnHP31Hj9x8CVQBmwGfiec261/9plwP/4Te9yzj0RyVpDJQUSSEtKZHN5B2+FrsgXEWkXRowYwbx586JdRouL2GF8M0sEHgBOAoYCF5rZ0BrNvgRynXMjgReB//W37QzcARwGjAPuMLNWvUIuMzXIxtI0b0E9exGRJomX68Kirbn/jpE8Zz8OWO6cW+mcKwGeA6qNSeice985V+Avfg7k+M9PBN52zm1zzm0H3gYmRbDW/WSmBtlQkgyWoJ69iEgTpKSksHXrVgV+Mznn2Lp1KykpKU1+j0gexu8NrAlZzsfrqdflCuCNerbt3aLVNSAjNciOonJIyVLPXkSkCXJycsjPz2fz5s3RLiXmpaSkkJOT03DDOkQy7GsbaLjWP+/MbAqQC3ynMdua2dXA1QB9+/ZtWpV1yEwNsmZbgUbRExFpomAwSP/+/aNdhhDZw/j5QJ+Q5RxgXc1GZnY88HPgdOdccWO2dc495JzLdc7ldu3atcUKB8hKDbKzsNSf5lZhLyIisSuSYT8bGGRm/c0sCZgMzAxtYGZjgL/hBf2mkJfeAk4ws07+hXkn+OtaTWZl2KtnLyIiMS5iYe+cKwN+iBfSi4AZzrmFZjbNzE73m/0OSAdeMLN5ZjbT33Yb8Gu8PxhmA9P8da0mMzVIQUk55SmdoECD6oiISOyK6H32zrnXgddrrPtlyPPj69n2MeCxyFVXv8y0IADFwUzS1LMXEZEYpuFy65CZ6oV9YSATSgugtHFTIIqIiLQVCvs6VIb9noQMb4V69yIiEqMU9nWoDPvdCf5kOLoiX0REYpTCvg6VYb/dpXsr1LMXEZEYpbCvQ2XYb6vww149exERiVEK+zpk+GG/uVw9exERiW0K+zoEExNITw6wsUwz34mISGxT2NcjMzXItuIECKZBoQbWERGR2KSwr0dGapCdhSUaH19ERGKawr4emakBf3z8TjpnLyIiMUthX49MzXwnIiJxQGFfD818JyIi8UBhX4+stCT17EVEJOYp7OuRmRqkqLSCsuQsKNoBFRXRLklERKTRFPb1qBxYpzCYBa7CC3wREZEYo7CvR+WQuXsTK2e+0732IiISexT29agM+13mh73O24uISAxS2Ncjyw/7nWh8fBERiV0K+3pU9uy3auY7ERGJYQr7elSG/ZbyDt4K9exFRCQGKezrUTXNbWkKWCIUbI1yRSIiIo2nsK9HYoLRMTnAzqIySO2kw/giIhKTFPYNyEwLsktD5oqISAxT2DcgMzXIDg2ZKyIiMUxh34Dqk+FoUB0REYk9CvsGaJpbERGJdQr7Buzr2XfSOXsREYlJCvsGZKaF9OzLiqCkINoliYiINIrCvgGZqUFKyiooTc7yVqh3LyIiMUZh34DKUfT2JGR6K3TeXkREYozCvgGVYb87oaO3Qj17ERGJMQr7BmRWzXznh7169iIiEmMU9g2oDPttTtPciohIbFLYNyArNQmALRX+zHcFGlhHRERii8K+AZU9++1FQFK6evYiIhJzFPYN6JgSwAx/Mpxs2Lsl2iWJiIg0isK+AQmV09wWlkJmDuzMj3ZJIiIijaKwD0PVKHqZObBzTbTLERERaRSFfRiyUpP8sO8Du9ZBeVm0SxIREQmbwj4MVXPaZ/UBVw6710e7JBERkbAp7MNQNfNdZh9vhQ7li4hIDFHYhyEjNehdjZ/V11uxQ2EvIiKxQ2Efhsqevcvo7a3Y+W10CxIREWkEhX0YstKClJY7CkmCDl3VsxcRkZiisA9D5Sh6Owp0+52IiMQehX0Yqma+q7xITz17ERGJIRENezObZGZLzGy5md1Wy+sTzWyumZWZ2bk1Xis3s3n+Y2Yk62xItbDP6uuNoudcNEsSEREJWyBSb2xmicADwHeBfGC2mc10zn0T0uxbYCpwcy1vUeicGx2p+hpjv559WSEUbIUOXaJcmYiISMMi2bMfByx3zq10zpUAzwFnhDZwzq1yzs0HKiJYR7NV79n799rv0BX5IiISGyIZ9r2B0JPb+f66cKWYWZ6ZfW5mZ7ZsaY2TmeaHfYEG1hERkdgTscP4gNWyrjEnuvs659aZ2QDgPTP72jm3otoHmF0NXA3Qt2/fplfagPSkAAnGvslwQBfpiYhIzIhkzz4f6BOynAOsC3dj59w6/+tK4ANgTC1tHnLO5Trncrt27dq8auuRkGBkVA6Zm9oJktLVsxcRkZgRybCfDQwys/5mlgRMBsK6qt7MOplZsv+8C3AE8E39W0VW1fj4Zt6hfM1rLyIiMSJiYe+cKwN+CLwFLAJmOOcWmtk0MzsdwMzGmlk+cB7wNzNb6G8+BMgzs6+A94F7alzF3+qqwh68i/R0gZ6IiMSISJ6zxzn3OvB6jXW/DHk+G+/wfs3tPgVGRLK2xqqa5ha8nn3+7OgWJCIiEiaNoBemzMqZ78Dr2Rduh+I90S1KREQkDAr7MFU7jK/b70REJIYo7MNUNc2tc/vCXrffiYhIDFDYhykzNUh5hWNvSfm+UfQ0r72IiMQAhX2YstIqp7ktgfQekBDU7XciIhITFPZhqjY+fkICZPbWYXwREYkJCvswZYSGPfgD6yjsRUSk7VPYh6myZ7/v9ru+6tmLiEhMUNiHKXO/nn0O7F4PZSVRrEpERKRhCvswZaUlAbCjIPReewe71kavKBERkTAo7MPUISmRxASrPj4+6Ip8ERFp8xT2YTIzjaInIiIxSWHfCJ07JLF1j3+OPtOfv0cX6YmISBunsG+E7hnJbNhV5C0Ekr3BdTSKnoiItHEK+0bonpHCxsqwB693r569iIi0cQr7RuiRkcKm3cWUVzhvRZYG1hERkbZPYd8IPTJTKK9wbN1T7K3I7ONdjV9REd3CRERE6qGwb4TuGSkA+87bZ/WF8hLYuzmKVYmIiNRPYd8IPSrDfqcf9rr9TkREYoDCvhF6ZHphX3WRXuXAOjt0Rb6IiLRdCvtG6JKeTGKC7TuMr569iIjEAIV9IyQmGN06JrNhp3+BXkoGJGfq9jsREWnTFPaNtN+99rr9TkRE2jiFfSP1yEjZdxgfoOdoWPUJFO+JXlEiIiL1UNg3Uo/MFDbuDAn7Qy6Fkt2w8OXoFSUiIlIPhX0jdc9IYXdxGXuLy7wVfcZB1yGQ93h0CxMREamDwr6RemQmAyED65hB7uWwbi6s/yqKlYmIiNROYd9IlaPoVTuUP/ICCKSqdy8iIm1SWGFvZjeYWYZ5HjWzuWZ2QqSLa4t61BwyFyA1C4afDV+/AMW7o1SZiIhI7cLt2X/PObcLOAHoClwO3BOxqtqwylH0qoU9wKFToWQPLHip9YsSERGpR7hhb/7Xk4HHnXNfhaxrV9KSAnRMCVQ/jA+QMxa6DdOhfBERaXPCDfs5ZvYfvLB/y8w6Au12Xtf97rWHfRfqrZ8H676MTmEiIiK1CDfsrwBuA8Y65wqAIN6h/HapR2YKG3YV7//CyPN1oZ6IiLQ54Yb9BGCJc26HmU0B/gfYGbmy2rbuGSn7H8YHSMmE4efA1y/uf6FeRQWU1rKNiIhIhIUb9g8CBWY2CvgpsBp4MmJVtXE9MlLYvKeY8gq3/4u5l0PpXpj3LOTnwSf3wT8mw//2hz8cBEXt9m8kERGJkkCY7cqcc87MzgD+7Jx71Mwui2RhbVn3zBTKKxxb9hRX3Xdfpfeh0H0EvHHLvnWdB0L/ibBoJix+DUZf1LoFi4hIuxZu2O82s9uBS4CjzCwR77x9u1R1r/3Oov3D3gxO+q0X6n3GQt/DoWN3cA7+PNK7NU9hLyIirSjcsL8AuAjvfvsNZtYX+F3kymrbQgfWGVVbg35HeI9QZt75/E/ug71boUN2xOsUERGBMM/ZO+c2AM8AmWZ2KlDknGu35+y7++Pjb6x5+11Dhp8DrhwW/SsCVYmIiNQu3OFyzwe+AM4Dzgdmmdm5kSysLevSIZlAgrGhtivy69N9OHQZDAva+XS4Kz/w7lgQEZFWEe5h/J/j3WO/CcDMugLvAO3yN3ZCgtGtY/L+A+s0pPJQ/gf3wK71kNEzMgVGS9EuSEqHhHr+htyyHJ69EEoLIJgKB5/SuM9wDjYugB4jmleriEg7Eu6tdwmVQe/b2oht41L3zJTGH8YHGHY24OCbf7Z4TVG1dQX8aTg8OxnKS2tvU1YCL10BgWToMRJe/j5sXtq4z1nwEkw/Eha92vyaRUTaiXAD+00ze8vMpprZVOA14PXIldX29chIafxhfICug71eaTxNmFNaCDMu9UJ+2Vvw6o1eD7ym9+/yhhM+/X648Fkv9J+7qHFjD8z6m/f14z/W/hkiIrKfcC/QuwV4CBgJjAIecs7dGsnC2rruGSlsrG3I3HAMPwfyZ8P2VS1aU9S8frN3aP38J2HiT+HLp+H9u6u3WfmhdyfCoVNhyKmQmQPnPwHbVsIr13gjDDZk3ZeQ/wX0HAVr8+DbzyKyOyIi8SbsQ/HOuZeccz92zt3knHslkkXFgh6ZKewpLmNPcVnjNx52tvd1YRz8M859ygv3ibfAoO/CMT+DMZfAR7+D2Y96bQq2wSvfhy6D4MTf7Nu235He8pLXvfYN+eJhCHaAi16AtGz45M+R2ScRkThTb9ib2W4z21XLY7eZ7Wrozc1skpktMbPlZnZbLa9PNLO5ZlZW8+p+M7vMzJb5jzY3Wl/owDqN1ukAb0rcxhzK374KSgoa/1mRtOFrr1fffyIcfbu3zgxO/RMMnuS9tujfMPN62LsFznkEkjpUf4/Dvg8jJ8MHv4Elb9b9WXu3elfwj5rsDVI07vuw9E3YtDhy+yciEifqDXvnXEfnXEYtj47OuYz6tvVH2XsAOAkYClxoZkNrNPsWmAr8o8a2nYE7gMOAccAdZtapMTsWaZUj5zXpIj3wDuVv+LrhC9TWzIanzoI/j4J7h8BbP/cuhou2op3eefrUTnDOY5CQuO+1xACc+xj0OsRrs/hVOP4O7/B7TWZw2p/8C/aurvvUxtwnoLwYxl3lLY+90pth8NO/tPiuiYjEm0heUT8OWO6cW+mcKwGeA84IbeCcW+Wcmw/UPGF7IvC2c26bc2478DYwKYK1NlqPzGb07AGGngkYLKzjnvv8OfD0ufDo8bD+K6/nPPAYmDUd/nKI9wfA4tegorxpn1+bPZvgs7/C7o31tyveDf+8FravhnMfh/Su+7dJ6gAXzYCuB3u9/PHX1f1+wVS44CnAwYtX7H81f3kZ5D3mHUHoNsRb1yEbDrkE5j8Pu9Y1ajdFRNqbcO+zb4rewJqQ5Xy8nnpTt+3dQnW1iNAhc5sko6d3zvrrF6DveC9od2+APRth40JY+T6kdobj74SxV0Fyurfd7g0w90nIe9y7kn3oGXDeE14PuTmKdsHTZ3tHG979lXch3RE3QEavfW0KtnlXw8+aDkU7vPPtB0yo+z07ZMM1H4MlNFxfp35w+n3wwlTv4r7j79z32tI3YecamPT/qm8z4TqY/YhXz3enNWp3RSTGOed1DCpKoaLM6xRUlIW/XFHub1+2b7mixnK112s8yutYX+39alk+7o76f29GSCTDvrbf7uHeKxXWtmZ2NXA1QN++fcOvrAWkJiWSkRJo+mF88A7lv3ojPBlywCOQ4gXscb+EcVdDcsfq23TsAd/5KRz5Y/j4Xi8YP74XjvpJ0+soK4Hnp8CmRd5tcWs+90I07zHvYrsxU7zrC/Ie96bvPegUOOrHkJPb8HuHHt5vyLCzYMX73m11/Y6CA4/z1n/xEGTkwOCTqrfv1M87QpL3uLf/KZnhf5ZIe+OcH1KlUF6y73lFqb+ujucVZV77quc1X6tcLgtZX3O5rPa2VaEZ+l5ldTwvDQngUnBh3METCZYIiUFICIQ8EiEh6H2tfM0SvVOaoe0Sg83vmDVRJMM+H+gTspwDhHu8NR84usa2H9Rs5Jx7CO+WQHJzc1v9pusemU28177SmCleeCd3hPTukN4NkjPC+2ZIDHhXwG9eAu/+GnqMgkHHN76Gigr413Xw3w/hzAe9GfkOucS7he7jP/pHER71eufDz4Ujb4LuNS+9aEGT7oE1s7zb8X7wiXc04b8fen/8JNby7XrEj7xTIXP+7h2JEGktVeFZAmXF+0K02qO0Cc9La19fUVp7m6r1fi31hXdrSAh4wVcZeonBGkEY9EMwpE0gpXqAVrUL7gvSmgHb4GuBMF8P7Ks5oWaQV4Z4yHKUwrq5Ihn2s4FBZtYfWAtMxps5LxxvAb8JuSjvBOD2li+xebx77ZsR9olBOOikhtvVxQxO/4sX+C99D67+ADoPaNx7vHsnfD0Djv1F9al3Ox3gXTg38WZY8gYceDx07t/0WsOVlOZdB/DwMd7tep36QWIyHFLHDRm9xnjn8j9/0Ltor+bV/hIfnPMDtdj7WvmoXK4M3NrWVX0t9o5iVQZobetCtykvCXktJMxD24d9sLIRKnuOicn+1+C+8Ask+2GV5D0CSZCYvi9AE5P2hVti0F8OhDyv2a4ydJOqB3C1sK1rmzqCO0bDMN5FLOydc2Vm9kO84E4EHnPOLTSzaUCec26mmY0FXgE6AaeZ2a+cc8Occ9vM7Nd4fzAATHPObYtUrU3VIyOFpRt3R7eIpDSY/DQ8dDQ8NwWufDv8wPt8unev+tgr6z4NkJmz7wr41tJ9qHd+/tWbvOVRF0GHLnW3P+IGePoc+E0v7zqHjj29IyYZPb0xDSpPB0jzlJdBWaEXhqWFUFbkPUqL9j2vbbmsyA/iopBt/eXykhqvhyyX1wj1lpKY5AVpIGlfoAaSQ9YleT3N5Ax/fWiw1twmJISrAjopJGxD2/rBGwhtExrOSft6qyItzFycDDmam5vr8vLyWvUz//CfJTzw/nKW3nUSgcQoTxWw/F145lzvHPa5j3l/XTvn3SK3a613xfruDf5jvbe89E1vIprzn2x7v2Ccgxcug2/+BVe9D70Pqb/90rdgw/zq+7jtv1C4DQad6F1M2OXA1qm9NTnnhWdpoTe5UNWjMORrYY11Rd7XsqKQ1wurr6sK7cJ9XyuaMIBUFfPuuggk+4eUR06+AAAYN0lEQVRsk/Zfrnxe9agM5eR9y6Ftq15LDmNdSEir5ylxxMzmOOcavIAqkofx4173jBQqHGzZU1J1K17UHHicd177nTthx7fe7XG71kLJnv3bVvZ+R18Mp/y+7QU9eL+Qz3rIuxCx1+iG2w8+0XuEKiv2rtT/8Hfw18PgsGu86xxSsyJTc33KSrz/i5K9IY+Q5dLKdQXe+tIC73mpv660wG9XsG+58tFoBsE0CKZ4XwMp1Z+ndvLXpdb/tXK7gB/aVeEdEuJVYa6QFYkmhX0zhN5+F/WwBzjiRm+kutWfeEPTDjzGOwyf0dt7dOzhXQgYbAO1hiOYEl7Q1yWQ7B3iH3UhvDsNPnsAvnoOhp3p3fHQsZd3qL9jL+8iyYoycOX+LTL+bTihPd+ywpAAriO0i3fX/lpjLo5KCHqnZ4IdvFMylc/TOkMwxwvlpDQ/sEOfp9b4GvJaZUgH07x/FwWvSLuisG+GagPr9GmgcWswgxPvbrhde5PeDc6437s24Z07vbENGjPTXn2CfhgnpfsPP5Qzc7w/ICrXJXWo5XllIKdXD/VAUsvUJiLiU9g3Q7OHzJXW1Ws0XPpP73nJXu/c/q513vn9kj377o0NvSVnv8PdqfvCOZgGCVG+VkNEJAwK+2bI7pBEMNGaPoqeRE9SB8ge6D1EROKcuiXNkJBgdOuYwsbmDKwjIiISYQr7Zuqekcy6nYXRLkNERKROCvtmGt47k/n5Oyktj9I4zSIiIg1Q2DfT4QOzKSgp56s1O6JdioiISK0U9s00fkA2ZvDpiq3RLkVERKRWCvtmykpLYlivDD5dsSXapYiIiNRKYd8CDh/Yhbmrd1BUWh7tUkRERPajsG8BEwZmU1JewZzV26NdioiIyH4U9i1gbL/OBBJMh/JFRKRNUti3gPTkAKP6ZPHJcl2kJyIibY/CvoUcPjCb+fk72FXUiNnNREREWoHCvoVMGJhNhYPZ/90W7VJERESqUdi3kEP6diI5kKD77UVEpM1R2LeQlGAiuf06KexFRKTNUdi3oMMHdmHR+l1s3VMc7VJERESqKOxb0ISB2QB8vlLn7UVEpO1Q2Legkb0zSU8O6H57ERFpUxT2LSiQmMC4/p35TOftRUSkDVHYt7DDB2azcste1u8sjHYpIiIigMK+xR0+sAuAevciItJmKOxb2ME9OtIpLaihc0VEpM1Q2LewhARjwsBs3lu8kY27iqJdjoiIiMI+Eq4/dhAlZRVc+UQehSWa415ERKJLYR8BQ3pmcN+FY1iwbic/njGPigoX7ZJERKQdU9hHyHFDuvPzk4fwxoIN/OHtJdEuR0RE2rFAtAuIZ1cc2Z8Vm/fywPsrGNAlnXMOzYl2SSIi0g6pZx9BZsa0M4Zx+MBsbnt5Pl9o+lsREYkChX2EBRMTePDiQ+nTKY0fPD2HolJdsCciIq1LYd8KMtOC/OzkIWzdW8Lcb7dHuxwREWlnFPatZNyAziQYfK6R9UREpJUp7FtJRkqQEb0z+Wylwl5ERFqXwr4VTRjYhXlrdlBQUhbtUkREpB1R2LeiCQOzKS135K3SeXsREWk9CvtWlHtAJwIJpkP5IiLSqhT2rahDcoBRfbI0/a2IiLQqhX0rO3xgNl+v3cnuotJolyIiIu2Ewr6VTRiQTXmFY/YqjaYnIiKtQ2Hfyg45oBNJiQk6lC8iIq1GYd/KUoKJHHJAli7SExGRVqOwj4IJA7qwcN0udhSURLsUERFpBxT2UTBhYDbOwSzNgiciIq0gomFvZpPMbImZLTez22p5PdnMnvdfn2Vm/fz1/cys0Mzm+Y/pkayztY3qk0lKUOftRUSkdQQi9cZmlgg8AHwXyAdmm9lM59w3Ic2uALY75w40s8nAb4EL/NdWOOdGR6q+aEoOJDK2X2eFvYiItIpI9uzHAcudcyudcyXAc8AZNdqcATzhP38ROM7MLII1tRnjB2SzZONutu4pjnYpIiIS5yIZ9r2BNSHL+f66Wts458qAnUC2/1p/M/vSzD40s6MiWGdUTBjo7ebnK3XeXkREIiuSYV9bD92F2WY90Nc5Nwb4MfAPM8vY7wPMrjazPDPL27x5c7MLbk0je2eSnhzg0xVbol2KiIjEuUiGfT7QJ2Q5B1hXVxszCwCZwDbnXLFzbiuAc24OsAIYXPMDnHMPOedynXO5Xbt2jcAuRE4gMYGx/TrpfnsREYm4SIb9bGCQmfU3syRgMjCzRpuZwGX+83OB95xzzsy6+hf4YWYDgEHAygjWGhUTBmazcvNe5qzWlLciIhI5EQt7/xz8D4G3gEXADOfcQjObZman+80eBbLNbDne4frK2/MmAvPN7Cu8C/eucc7F3cntM0b3JqdTKhc/8jlvLtgQ7XJERCROmXM1T6PHptzcXJeXlxftMhpt8+5irnwyj/n5O/j5yUO44sj+tJMbEkREpJnMbI5zLrehdhpBL8q6dkzmuavGc+LQHtz12iLumLmQsvKKaJclIiJxRGHfBqQmJfLXiw/h6okDePKz1Vz91ByNmy8iIi1GYd9GJCQYPzt5CL8+czgfLt3MMb//gGdmraa8Ij5Os4iISPQo7NuYS8YfwKvXH8ng7h35+SsLOP3+j8lbFXfXJoqISCtS2LdBQ3pm8NzV4/nLhWPYtreEc6d/xo3PfalD+yIi0iQRmwhHmsfMOG1UL44b0o0HP1jB9A9XEEhM4PfnjYp2aSIiEmPUs2/j0pIC/OSEg7h0Qj9enpvPys17ol2SiIjEGIV9jPjB0QNJDiTyp3eWRbsUERGJMQr7GNElPZmpR/Tj3/PXsWTD7miXIyIiMURhH0O+P3EA6UkB/vj20miXIiIiMURhH0Oy0pL43pH9eXPhBhas3RntckREJEYo7GPMFUf1JzM1yL3q3YuISJgU9jEmIyXI1RMH8N7iTZoaV0REwqKwj0FTD+9HdocknbsXEZGwKOxjUIfkAD84eiAfL9/CZyu2RrscERFp4xT2MWrK+APonpHMPW8sokKT5YiISD0U9jEqJZjIT088mK/yd/Lyl2ujXY6IiLRhCvsYdtaY3ozuk8Vv31zMnuKyaJcjIiJtlMI+hiUkGHeePozNu4u5/73l0S5HRETaKIV9jBvdJ4tzDsnhsY//y6ote6NdjoiItEEK+zhw66SDCCYad732TbRLERGRNkhhHwe6ZaRw/XGDeGfRJj5cujna5YiISBujsI8Tlx/Rj37Zafz61W8oLa+IdjkiItKGKOzjRHIgkf85ZSjLN+3hiU9XRbscERFpQxT2ceS4Id049uBu/O9bS/g6X7PiiYiIR2EfR8yM3507kq7pyVzz9By27S2JdkkiItIGKOzjTHZ6Mg9OOYTNe4r50bNfUq6hdEVE2j2FfRwamZPFXWcM5+PlW/j9f5aEvV1ZeQUL1+nwv4hIvFHYx6nzx/bhwnF9efCDFby5YH1Y29wxcyGn3Pcxz8xaHeHqRESkNSns49idpw9lVJ8sfjLjK5Zv2lNv2zcXrOeZWd/SuUMSd/xrIbNWaupcEZF4obCPY8mBRKZPOYSUYCJXPDGb/O0FtbZbu6OQn744n5E5mbx900T6Zqfxg2fmsmZb7e1FRCS2KOzjXM/MVB65LJfte0s498HPWL5pd7XXy8oruOm5eZRXOO6bPIbs9GQeuTSX0vIKrnoyj4ISzaYnIhLrFPbtwJi+nXj++xMoq3CcN/0z5ufvqHrt/veX88Wqbdx11nD6dekAwICu6dx/0SEs3bibn8z4igpd0S8iEtMU9u3EkJ4ZvHjNBDokB7jo4Vl8tmIrs1dt4753l3H2mN6cNSanWvvvDO7K7ScN4Y0FG/iLps8VEYlpgWgXIK2nX5cOvHjN4Ux5dBaXPf4FGSlB+nZOY9qZw2ttf+VR/Vm0YRd/fGcpycEEvj9xAGbWylWLiEhzqWffzvTITGHG9ydwcI+O7Cws4b4Lx5CeXPvffGbGb84awSkjenLPG4v54T++ZG+xzuGLiMQacy4+zsfm5ua6vLy8aJcRM4pKy9m8u5g+ndMabOuc46GPVvLbNxdzYLd0/nZJLv398/siIhI9ZjbHOZfbYDuFvYTr42Vb+OGzcymvcPzpgtEM753Jso17WLZpN8s27WHVlr2MH5DN1RMHkBJMrPU9yiscL83JxwzOy+3TynsgIhJfFPYSEWu2FXDN03NYuG5XtfWZqUF6ZqaweMNu+mWn8eszh3PUoK7V2ny6YgvT/v0Nizd4t//96YLRnDmmd6vVLiISbxT2EjFFpeU89dlqkoMJHNgtnUHdOtIlPQkz46Olm/nlvxawamsBp4zsyS9PHUpJWQV3v7aINxduoHdWKreddDD/mPUtc1Zv5x9XHUZuv87R3iURkZiksJeoKSotZ/qHK/jrBysIJhilFY5EM649eiBX+Yf4dxSUcNZfP2VnYSn/vPYI+mY3fO2AiIhUp7CXqFu1ZS+//88S0pIS+fF3D6JHZkq11/+7ZS9nPvAJ3Tom89K1h5OREoxSpSIisUlhLzHhsxVbueTRWUwYmM3jU8cSSNTdoCIi4Qo37PWbVaJqwsBs7j5rOP+3bAu3vDif1Vv31tm2tLyC9xdv4t7/LGHZxt11thMRkeo0gp5E3QVj+5K/vZC/vLecV75cy6g+WZw2sienjuxF94xk5n67g3/NW8tr89ezdW8JAH95fzlnju7NjccP4oBs3fMvIlIfHcaXNmPtjkJe/Wod/56/jgVrd2EGXdKT2by7mORAAscP6c4Zo3sxqk8Wj33yX574dBVl5Y7zcvtw/bEH0isrNdq7ICLSqtrEOXszmwT8GUgEHnHO3VPj9WTgSeBQYCtwgXNulf/a7cAVQDnwI+fcW/V9lsI+vqzYvIdXv1rPko27OOagbkwa3oOONS7g27SriL9+sIJ/zPoWgO8c1JUTh/XguIO70alDUjTKFhFpVVEPezNLBJYC3wXygdnAhc65b0LaXAuMdM5dY2aTgbOccxeY2VDgWWAc0At4BxjsnCuv6/MU9u3X2h2FPPJ/K3lzwQbW7ywiMcEY268TJwztwYicTHpnpdKtY7Iu/hORuNMWwn4CcKdz7kR/+XYA59z/C2nzlt/mMzMLABuArsBtoW1D29X1eQp7cc7x9dqd/GfhRv7zzQaWbtxT9VpigtEjI4XeWalkpAZJChiBhASCiQkkBYzEBCPRjISQrwlmmEGCgWEkGGCGQdVr/qqq2QDNb1v5WuU62Lc+lPnvV73dvvcLXV/5WuWKmttVe19sv9dCm4XWVMvG4ayqqj+ctrXWWE/dDbVrjHBnagz3Y8Ktp9Z/22a/Z9M1f8LKlp3xMhITaLbWnJzNmf1zVE4m3TJSGm4Yfi1hhX0kL9DrDawJWc4HDqurjXOuzMx2Atn++s9rbLvfuKpmdjVwNUDfvn1brHCJTWbGyJwsRuZkcfOJB7FmWwErt+xl3Y5C1m4vZN2OQvJ3FLJ+ZyGl5RWUljtKyiooLa+grMJRXuGoqHBUOEe5c1RUgMPhHFQ4hwPi5BIXEYmShy45lBOG9Wj1z41k2Nf2p0/NX5V1tQlnW5xzDwEPgdezb2yBEt/6dE4La1a/xnJu/z8AKv8oIGR53/N920Ho8r6F2tqHblO5navRfv+fihrvX7Uu5H3q3pTajvQ15g+c2tq6Wj6p9nbh1VPnZ4dZT/hbN/39GvPLKPz3bPqvuOb+kdrSf+Q2Z1/qfM8YSYBI/E4KRyTDPh8IndYsB1hXR5t8/zB+JrAtzG1FosIqD++32kFDEZHmieQVS7OBQWbW38ySgMnAzBptZgKX+c/PBd5z3p/yM4HJZpZsZv2BQcAXEaxVREQkbkWsZ++fg/8h8BberXePOecWmtk0IM85NxN4FHjKzJbj9egn+9suNLMZwDdAGXBdfVfii4iISN00qI6IiEiM0tj4IiIiAijsRURE4p7CXkREJM4p7EVEROKcwl5ERCTOKexFRETinMJeREQkzsXNffZmthlY3cJv2wXY0sLvGS3al7YrnvYnnvYF4mt/tC9tV3P25wDnXNeGGsVN2EeCmeWFM1hBLNC+tF3xtD/xtC8QX/ujfWm7WmN/dBhfREQkzinsRURE4pzCvn4PRbuAFqR9abviaX/iaV8gvvZH+9J2RXx/dM5eREQkzqlnLyIiEucU9rUws0lmtsTMlpvZbdGup7HM7DEz22RmC0LWdTazt81smf+1UzRrDJeZ9TGz981skZktNLMb/PUxtz9mlmJmX5jZV/6+/Mpf39/MZvn78ryZJUW71nCZWaKZfWlmr/rLsbwvq8zsazObZ2Z5/rqY+z4DMLMsM3vRzBb7PzsTYnhfDvL/Tyofu8zsxhjen5v8n/8FZvas/3sh4j83CvsazCwReAA4CRgKXGhmQ6NbVaP9HZhUY91twLvOuUHAu/5yLCgDfuKcGwKMB67z/z9icX+KgWOdc6OA0cAkMxsP/Bb4o78v24ErolhjY90ALApZjuV9ATjGOTc65DaoWPw+A/gz8KZz7mBgFN7/UUzui3Nuif9/Mho4FCgAXiEG98fMegM/AnKdc8OBRGAyrfFz45zTI+QBTADeClm+Hbg92nU1YT/6AQtClpcAPf3nPYEl0a6xifv1L+C7sb4/QBowFzgMbzCNgL++2vdfW34AOXi/ZI8FXgUsVvfFr3cV0KXGupj7PgMygP/iX5MVy/tSy76dAHwSq/sD9AbWAJ2BgP9zc2Jr/NyoZ7+/yv+MSvn+uljX3Tm3HsD/2i3K9TSamfUDxgCziNH98Q97zwM2AW8DK4Adzrkyv0ksfb/9CfgpUOEvZxO7+wLggP+Y2Rwzu9pfF4vfZwOAzcDj/imWR8ysA7G5LzVNBp71n8fc/jjn1gK/B74F1gM7gTm0ws+Nwn5/Vss63bIQZWaWDrwE3Oic2xXteprKOVfuvMOROcA4YEhtzVq3qsYzs1OBTc65OaGra2na5vclxBHOuUPwTuFdZ2YTo11QEwWAQ4AHnXNjgL3EwCHuhvjnsU8HXoh2LU3lX1dwBtAf6AV0wPt+q6nFf24U9vvLB/qELOcA66JUS0vaaGY9Afyvm6JcT9jMLIgX9M845172V8fs/gA453YAH+Bdh5BlZgH/pVj5fjsCON3MVgHP4R3K/xOxuS8AOOfW+V834Z0THkdsfp/lA/nOuVn+8ot44R+L+xLqJGCuc26jvxyL+3M88F/n3GbnXCnwMnA4rfBzo7Df32xgkH91ZBLeYaOZUa6pJcwELvOfX4Z37rvNMzMDHgUWOefuDXkp5vbHzLqaWZb/PBXvB38R8D5wrt8sJvbFOXe7cy7HOdcP72fkPefcxcTgvgCYWQcz61j5HO/c8AJi8PvMObcBWGNmB/mrjgO+IQb3pYYL2XcIH2Jzf74FxptZmv+7rfL/JuI/NxpUpxZmdjJeLyUReMw5d3eUS2oUM3sWOBpvJqWNwB3AP4EZQF+8b7jznHPbolVjuMzsSOD/gK/Zd274Z3jn7WNqf8xsJPAE3vdVAjDDOTfNzAbg9Y47A18CU5xzxdGrtHHM7GjgZufcqbG6L37dr/iLAeAfzrm7zSybGPs+AzCz0cAjQBKwErgc/3uOGNsXADNLw7uWaoBzbqe/Llb/b34FXIB3p9GXwJV45+gj+nOjsBcREYlzOowvIiIS5xT2IiIicU5hLyIiEucU9iIiInFOYS8iIhLnFPYiEnFmdnTlzHgi0voU9iIiInFOYS8iVcxsipl94c8b/jd/4p49ZvYHM5trZu+aWVe/7Wgz+9zM5pvZK5XziZvZgWb2jpl95W8z0H/79JA51p/xRxATkVagsBcRAMxsCN7IXkf4k/WUAxfjTdYx158k5kO8ERkBngRudc6NxBvhsHL9M8ADzrlReON+r/fXjwFuBIbizcx2RMR3SkQAb1hIERHwxuk+FJjtd7pT8SYXqQCe99s8DbxsZplAlnPuQ3/9E8AL/vjyvZ1zrwA454oA/Pf7wjmX7y/PA/oBH0d+t0REYS8ilQx4wjl3e7WVZr+o0a6+MbbrOzQfOtZ3Ofr9I9JqdBhfRCq9C5xrZt0AzKyzmR2A93uickaui4CP/clItpvZUf76S4APnXO7gHwzO9N/j2R/EhMRiSL9ZS0iADjnvjGz/wH+Y2YJQClwHbAXGGZmc4CdeOf1wZuKc7of5pUzq4EX/H8zs2n+e5zXirshIrXQrHciUi8z2+OcS492HSLSdDqMLyIiEufUsxcREYlz6tmLiIjEOYW9iIhInFPYi4iIxDmFvYiISJxT2IuIiMQ5hb2IiEic+/+lzSidCQHR/gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#勾配降下をMomentamで行った\n",
    "#収束が早い\n",
    "model2.plot_learning_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = ScratchDeepNeuralNetrowkClassifier2(n_features=n, batch_size=50, epoch=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.add(\"FC\", 400, XavierInitializer(), Adam(lr=0.001, beta1=0.9, beta2=0.99))\n",
    "model3.add(\"Tanh\")\n",
    "model3.add(\"FC\", 400, XavierInitializer(), Adam(lr=0.001, beta1=0.9, beta2=0.99))\n",
    "model3.add(\"Tanh\")\n",
    "model3.add(\"FC\", 400, XavierInitializer(), Adam(lr=0.001, beta1=0.9, beta2=0.99))\n",
    "model3.add(\"Tanh\")\n",
    "model3.add(\"FC\", 200, XavierInitializer(), Adam(lr=0.001, beta1=0.9, beta2=0.99))\n",
    "model3.add(\"Tanh\")\n",
    "model3.add(\"FC\", 200, XavierInitializer(), Adam(lr=0.001, beta1=0.9, beta2=0.99))\n",
    "model3.add(\"Tanh\")\n",
    "model3.add(\"FC\", 100, XavierInitializer(), Adam(lr=0.001, beta1=0.9, beta2=0.99))\n",
    "model3.add(\"Tanh\")\n",
    "model3.add(\"FC\", 100, XavierInitializer(), Adam(lr=0.001, beta1=0.9, beta2=0.99))\n",
    "model3.add(\"Tanh\")\n",
    "model3.add(\"FC\", 10, XavierInitializer(), Adam(lr=0.001, beta1=0.9, beta2=0.99))\n",
    "model3.add(\"Softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 train_loss: 0.20047947947184244 val_loss: 0.21675984774798368 acc: 0.10216666666666667\n",
      "epoch:2 train_loss: 0.147649112701416 val_loss: 0.1820328305480047 acc: 0.10216666666666667\n",
      "epoch:3 train_loss: 0.10643446159362793 val_loss: 0.15016149951632807 acc: 0.10216666666666667\n",
      "epoch:4 train_loss: 0.09567005157470704 val_loss: 0.1463943340791228 acc: 0.10216666666666667\n",
      "epoch:5 train_loss: 0.06966157658894857 val_loss: 0.12999290392276278 acc: 0.10216666666666667\n",
      "epoch:6 train_loss: 0.06545148118336995 val_loss: 0.1282480881990596 acc: 0.10216666666666667\n",
      "epoch:7 train_loss: 0.056506895542144775 val_loss: 0.1140373295413604 acc: 0.10216666666666667\n",
      "epoch:8 train_loss: 0.04453244137763977 val_loss: 0.12197214577978883 acc: 0.10216666666666667\n",
      "epoch:9 train_loss: 0.0545103751818339 val_loss: 0.12754291767693154 acc: 0.10216666666666667\n",
      "epoch:10 train_loss: 0.0439989321231842 val_loss: 0.12122807984219948 acc: 0.10216666666666667\n"
     ]
    }
   ],
   "source": [
    "model3.fit(X_train.astype(\"f\"), y_train.astype(\"f\"), X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#勾配降下をadamで行った\n",
    "#学習率高い(0.01)と収束しなかった。収束早い。beta2を下げると学習が進んだ時の学習率が低下？。　エポック５０で爆発した\n",
    "\n",
    "model3.plot_learning_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.101"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#テストのaccracy\n",
    "test_pred = model3.predict(X_test)\n",
    "model3.accuracy(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Momentum SGD\n",
    "黒い線が損失関数の等高線を表していて、紫の星印で最小値となっているとします。Gradient Decent の更新式 (1.12) に従えば、傾きが最小の方向に突っ込んでいくためジグザグ運動が始まり、なかなか目的の星印にたどり着けなくなっています。しかし、よく観察してみると、行ったり来たりしている部分の\"平均\"をとればジグザグ運動は相殺されて前方への推進力（右図の青矢印）が得られそうです。これが、Momentum SGD の発想です。\n",
    "https://qiita.com/deaikei/items/29d4550fa5066184329a\n",
    "γは0.9 程度に設定されることが多いようです。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 3, 3])"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
