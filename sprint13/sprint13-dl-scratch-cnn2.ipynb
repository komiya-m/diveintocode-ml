{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "        self.Z = 0\n",
    "        self.dA = 0\n",
    "        self.dW = 0\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        self.Z = deepcopy(X)\n",
    "        A = np.dot(X, self.W) + self.B\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        self.dA = deepcopy(dA)\n",
    "        self.dW = np.dot(self.Z.T, dA) / len(self.dA)\n",
    "        dZ = np.dot(dA, self.W.T) \n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     48,
     90
    ]
   },
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sigma=0.01):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2=None):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W : 次の形のndarray, shape(n_nodes1, n_nodes2)\n",
    "        \"\"\"\n",
    "        if n_nodes2 is None:\n",
    "            W = self.sigma * np.random.randn(n_nodes1, 1)\n",
    "        else:\n",
    "            W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "            \n",
    "        return W.astype(\"f\")\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : 次の形のndarray, shape(1, nodes2)\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B.astype(\"f\")\n",
    "    \n",
    "class XavierInitializer:\n",
    "    \"\"\"\n",
    "    Xavierによる初期化\n",
    "    Sigmoid」かTanhに向いている\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sigma = None\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W : 次の形のndarray, shape(n_nodes1, n_nodes2)\n",
    "        \"\"\"\n",
    "        self.sigma = 1 / np.sqrt(n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W.astype(\"f\")\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : 次の形のndarray, shape(1, nodes2)\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B.astype(\"f\")\n",
    "    \n",
    "class HeInitializer:\n",
    "    \"\"\"\n",
    "    Heによる初期化\n",
    "    ReLUと相性がいい\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sigma = 0\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W : 次の形のndarray, shape(n_nodes1, n_nodes2)\n",
    "        \"\"\"\n",
    "        self.sigma = np.sqrt(2 / n_nodes1)\n",
    "        W = (self.sigma * np.random.randn(n_nodes1, n_nodes2))\n",
    "        return W.astype(\"f\")\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : 次の形のndarray, shape(1, nodes2)\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B.astype(\"f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "code_folding": [
     0,
     25,
     57,
     95
    ]
   },
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "        layer.W[...] = layer.W - self.lr * layer.dW\n",
    "        layer.B[...] = layer.B - self.lr * np.mean(layer.dA, axis=0, keepdims=True)\n",
    "        return layer\n",
    "\n",
    "class AdaGrad:\n",
    "    \"\"\"\n",
    "    学習率を変化を減少させていく勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.HW = 0\n",
    "        self.HB = 0\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "        \n",
    "        dW = np.dot(layer.Z.T, layer.dA) / len(layer.dA)\n",
    "        dB = np.mean(layer.dA, axis=0)\n",
    "        self.HW += dW**2\n",
    "        self.HB +=  dB**2\n",
    "        layer.W[...] = layer.W - self.lr / np.sqrt(self.HW +1e-7) * dW #0で割るとまずいので +le-7\n",
    "        layer.B[...] = layer.B - self.lr / np.sqrt(self.HB + 1e-7)  * dB\n",
    "        return layer\n",
    "    \n",
    "class Momentum:\n",
    "    \n",
    "    \"\"\"\n",
    "    momentumSGD\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    momentum : 学習係数\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.vW = 0\n",
    "        self.vB = 0\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "\n",
    "        dW = np.dot(layer.Z.T, layer.dA) / len(layer.dA)\n",
    "        dB = np.mean(layer.dA, axis=0)\n",
    "        \n",
    "        self.vW = self.momentum * self.vW - self.lr * dW\n",
    "        self.vB =  self.momentum * self.vB - self.lr * dB\n",
    "        \n",
    "        layer.W[...] = layer.W + self.vW\n",
    "        layer.B[...] = layer.B + self.vB\n",
    "        \n",
    "        return layer\n",
    "    \n",
    "class Adam:\n",
    "\n",
    "    \"\"\"\n",
    "    Adam\n",
    "    RMSprop に Momentum 法を組み合わせたような形\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    momentum : 学習係数\n",
    "    beta1\n",
    "    beta2\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iter = 0\n",
    "        self.mW = 0\n",
    "        self.vW = 0\n",
    "        self.mB = 0\n",
    "        self.vB = 0\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \n",
    "        self.iter += 1\n",
    "        dW = np.dot(layer.Z.T, layer.dA) / len(layer.dA)\n",
    "        dB = np.mean(layer.dA, axis=0)\n",
    "        \n",
    "        lr_t  = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter) \n",
    "        \n",
    "        self.mW += (1 - self.beta1) * (dW - self.mW)\n",
    "        self.vW += (1 - self.beta2) * (dW**2 - self.vW)\n",
    "        self.mB += (1 - self.beta1) * (dB - self.mB)\n",
    "        self.vB += (1 - self.beta2) * (dB**2 - self.vB)\n",
    "        \n",
    "        layer.W -= lr_t * self.mW / (np.sqrt(self.vW) + 1e-7)\n",
    "        layer.B -= lr_t * self.mB / (np.sqrt(self.vB) + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0,
     39,
     78,
     123
    ]
   },
   "outputs": [],
   "source": [
    "class sigmoid:\n",
    "    \"\"\"\n",
    "    シグモイド関数\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.Z = 0\n",
    "    \n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        Z = 1 / (1 + np.exp(-A))\n",
    "        self.Z = Z\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        dA = dZ  *  (1 - self.Z) * self.Z \n",
    "        return dA\n",
    "    \n",
    "class Tanh:\n",
    "    \"\"\"\n",
    "    ハイパボリックタンジェント関数\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.Z = 0\n",
    "    \n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        Z = np.tanh(A)\n",
    "        self.Z = Z\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        dA = dZ  *  (1 - self.Z**2)\n",
    "        return dA\n",
    "\n",
    "class Softmax:\n",
    "    \"\"\"\n",
    "    ソフトマックス関数\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.Z = 0\n",
    "    \n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        \n",
    "        c = np.max(A)\n",
    "        A = A - c\n",
    "        ex = np.exp(A)\n",
    "        Z = ex / (np.sum(ex, axis=1))[:, np.newaxis]\n",
    "        self.Z = Z\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, y):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : 次の形のndarray, shape (batch_size, n_class)\n",
    "            正解ラベル\n",
    "        Returns\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_class)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        \n",
    "        dA = self.Z - y\n",
    "        \n",
    "        return dA\n",
    "    \n",
    "class ReLU:\n",
    "    \"\"\"\n",
    "    ReLU関数\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.Z = None\n",
    "    \n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        Z = np.maximum(0, A)\n",
    "        self.Z = deepcopy(Z)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        \n",
    "        dA = dZ  *  np.where(self.Z != 0, 1, self.Z)\n",
    "        \n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self.X = X[shuffle_index]\n",
    "        self.y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    \n",
    "    #Pythonの特殊メソッドのひとつで、オブジェクトに角括弧でアクセスしたときの挙動を定義できる。\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self.X[p0:p1], self.y[p0:p1]        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self.X[p0:p1], self.y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class ScratchDeepNeuralNetrowkClassifier2:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_features, batch_size=50, epoch=10, verbose=True, metrics=\"acc\"):\n",
    "        self.n_nodes = [n_features]\n",
    "        #self.n_output = n_output\n",
    "        self.batch_size = batch_size\n",
    "        self.epoch = epoch\n",
    "        self.metrics = metrics\n",
    "        self.verbose = verbose\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        self.layers = []\n",
    "\n",
    "    \n",
    "    def add(self, layer_type, n_nodes=None, Initializer=None, optimizer=None):\n",
    "        \n",
    "        if layer_type == \"FC\":\n",
    "            self.layers += [FC(self.n_nodes[-1], n_nodes, Initializer, optimizer)]\n",
    "            self.n_nodes += [n_nodes]\n",
    "            \n",
    "        elif layer_type == \"Conv1d\":\n",
    "            salf.layers += [SimpleConv1d(filter_size=3, in_channel=1, initializer=initializer, optimizer=optimizer, straid=1, pad=0, out_channel=1)]\n",
    "            self.n_nodes += [n_nodes]\n",
    "            \n",
    "        elif layer_type == \"ReLU\":\n",
    "            self.layers += [ReLU()]\n",
    "        \n",
    "        elif layer_type == \"Tanh\":\n",
    "            self.layers += [Tanh()]\n",
    "        \n",
    "        elif layer_type == \"sigmoid\":\n",
    "            self.layers += [sigmoid()]\n",
    "            \n",
    "        elif layer_type == \"Softmax\":\n",
    "            self.layers += [Softmax()]\n",
    "        else:\n",
    "            print(\"layer_typeが存在しません\")\n",
    "    \n",
    "    def add_sim(self, layer):\n",
    "        \n",
    "        self.layers += [layer]\n",
    "            \n",
    "    def fit(self, X, y, X_val=None, y_val=None, epoch=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            学習用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        epoch : int\n",
    "            エポック数変えたいときは入れてください\n",
    "        \"\"\"\n",
    "        if epoch:\n",
    "            self.epoch = epoch\n",
    "        \n",
    "        for i in range(self.epoch):\n",
    "\n",
    "            #バッチ作成\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=56)\n",
    "\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                \n",
    "                #FP\n",
    "                self.FP(mini_X_train)\n",
    "\n",
    "                #BP\n",
    "                self.BP(mini_y_train)\n",
    "                \n",
    "            #評価値等の表示\n",
    "            train_pred = self.FP(X)\n",
    "            self.train_loss += [self._cross_entropy_loss(train_pred, y)]\n",
    "            \n",
    "            if np.any(X_val):\n",
    "                val_pred = self.FP(X_val)\n",
    "                self.val_loss += [self._cross_entropy_loss(val_pred, y_val)]\n",
    "                \n",
    "                #metricsを判定\n",
    "                if  self.metrics == \"acc\":\n",
    "                    met = self.accuracy(np.argmax(y_val, axis=1), np.argmax(val_pred, axis=1))\n",
    "                else:\n",
    "                    print(\"metricsの入力が間違っています\")\n",
    "                      \n",
    "                if self.verbose:\n",
    "                    print(\"epoch:{0} train_loss: {1} val_loss: {2} {3}: {4}\".format(i+1, self.train_loss[i], self.val_loss[i], self.metrics, met))\n",
    "                    \n",
    "            else:\n",
    "                if self.verbose:\n",
    "                      print(\"epoch:{0} loss: {1}\".format(i+1, self.train_loss[i]))\n",
    "     \n",
    "    def FP(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "            \n",
    "        return X\n",
    "            \n",
    "    def BP(self, y):\n",
    "        for layer in reversed(self.layers):\n",
    "            y = layer.backward(y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        hx = self.FP(X)\n",
    "        return np.argmax(hx, axis=1)\n",
    "            \n",
    "    def _cross_entropy_loss(self,z, y):\n",
    "        z += 1e-7\n",
    "        return - sum(sum(y * np.log(z))) / len(y)\n",
    "    \n",
    "    def accuracy(self, y, y_pred):\n",
    "        # accuracyを計算して返す\n",
    "        return accuracy_score(y, y_pred)\n",
    "    \n",
    "    def plot_learning_curve(self):\n",
    "        \"\"\"\n",
    "        学習曲線をプロットします。\n",
    "\n",
    "        loss : array\n",
    "        一回ごとの勾配降下方のロスのログ(train)\n",
    "         val_los : array\n",
    "        一回ごとの勾配降下方のロスのログ(val or test)\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.title(\"model_loss\")\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.plot(self.train_loss, label=\"train_loss\")\n",
    "        plt.plot(self.val_loss, label=\"val_loss\")\n",
    "        #plt.yscale(\"log\")\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class SimpleConv1d:\n",
    "    \"\"\"\n",
    "    convolutional layee\n",
    "    Parameters\n",
    "    ----------\n",
    "    filter_size : int\n",
    "      フィルターのサイズ\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, filter_size, in_channel, initializer, optimizer, straid=1, pad=0, out_channel=1):\n",
    "        self.optimizer = optimizer\n",
    "        self.filter_size = filter_size\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(filter_size*in_channel, out_channel) #shape(filter_size*in_channel, out_cannel)\n",
    "        self.B = initializer.B(out_channel).reshape(1,-1) #shape(1, out_cannel)\n",
    "        self.out_size = None\n",
    "        self.out_channel = out_channel\n",
    "        self.straid = straid\n",
    "        self.CX = 0\n",
    "        self.dA = 0 #shape(batch_size, out_size)\n",
    "        self.dW = 0 \n",
    "        self.m = 0\n",
    "        self.n = 0\n",
    "        self.c = in_channel\n",
    "        self.pad = pad\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size,  n_feture, n_chanel)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, out_size, out_chanel)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        if X.ndim is 1:\n",
    "            X = X[np.newaxis, :, np.newaxis]\n",
    "        elif X.ndim is 2:\n",
    "            X = X[:, :, np.newaxis]\n",
    "        self.m = X.shape[0]\n",
    "        self.n = X.shape[1]\n",
    "        self.c = X.shape[2]\n",
    "        #out_sizeの計算\n",
    "        if self.out_size is None:\n",
    "            self.out_size = int((self.n + 2*self.pad - self.filter_size) / self.straid + 1)\n",
    "        \n",
    "        #並列計算のためXからデータを抜き出す CX shape(out_size*batch_size, filter_size*in_chanel)\n",
    "        #CX = np.empty((0, self.filter_size*self.c))\n",
    "        #for i in range(self.m):\n",
    "            #CX = np.vstack((CX, np.array([X[i, j*self.straid : j*self.straid+self.filter_size, k] for j in range(self.out_size) for k in range(self.c)]).reshape(-1, self.filter_size*self.c)))\n",
    "        indar = np.array([np.arange(j * self.straid, j*self.straid+self.filter_size) for j in range(self.out_size)])\n",
    "        #CX = X[:, :, ar].reshape(self.m*self.out_size, self.filter_size) \n",
    "        CX = X[:, indar, : ].reshape(self.out_size*self.m, self.filter_size*self.c).astype(\"f\")\n",
    "        self.CX = CX #shape(self.out_size*self.m, self.filter_size*self.c)\n",
    "        \n",
    "        A = np.dot(CX, self.W) + self.B #ここのA shape(batch_size*out_size, out_cahnnel)\n",
    "        A = A.reshape(self.m, self.out_size, self.out_channel) #ここのA shape(batch_size, out_size, out_cahnnel)\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size,out_size,out_channel)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size,n_feture, in_channel)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        if dA.ndim is 1:\n",
    "            dA = dA[np.newaxis, :, np.newaxis]\n",
    "        elif dA.ndim is 2:\n",
    "            dA = dA[:, :, np.newaxis]\n",
    "            \n",
    "        self.dA = np.sum(dA, axis=1)\n",
    "        self.dW = np.dot(self.CX.T, dA.reshape(-1,self.out_channel)) #dAを shape(out_size*batch_size, out_channel)へ変形\n",
    "        \n",
    "        #ここからdZの計算\n",
    "        #dZの並列計算のためにdAのアレーを作成\n",
    "        da_ar = np.empty((0, self.filter_size*self.out_channel))\n",
    "        for i in range(self.m): #サンプル数分ループ\n",
    "            for j in range(self.n):\n",
    "                dalist = []\n",
    "                for k in range(self.out_channel):\n",
    "                    for s in range(self.filter_size):\n",
    "                        if  ((j - s) / self.straid < 0) or (j - s > self.out_size -1) or ((j - s) % self.straid  != 0):\n",
    "                            dalist += [0]\n",
    "                        else:\n",
    "                            dalist += [dA[i, j-s, k]]\n",
    "        \n",
    "                dalist = np.array(dalist)\n",
    "                da_ar = np.vstack((da_ar, dalist)) #da_ar shape(batch_size*X_fetures, filter_size*out_channel)\n",
    "        #indar = np.array([np.arange(j * self.straid, j*self.straid+self.filter_size) for j in range(self.out_size)])\n",
    "        #Wのshapeを変形(filter_size*out_channel, in_channel)\n",
    "        #ar = np.array([np.arange(i*self.straid,i*self.straid+self.filter_size)[::-1] for i in range(self.out_size)])\n",
    "        #dA = dA[:, ar, :].transpose(0,1,3,2).reshape(-1,self.filter_size*self.out_channel)\n",
    "\n",
    "        W = self.W.T.reshape(self.c, self.out_channel, self.filter_size).transpose(1,0,2).reshape(self.c, -1).T\n",
    "        dZ = np.dot(da_ar, W).reshape(self.m, self.n, self.c)\n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return dZ\n",
    "    \n",
    "    def get_out_put_size(n_in, pad, filter_size, straid):\n",
    "        #一次元畳み込み後の出力サイズの計算\n",
    "        n_out = (n_in + 2*pad - filter_size) / straid + 1 \n",
    "        return n_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】平滑化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    #フラットにするだけのレイヤー\n",
    "    def __init__(self):\n",
    "        self.shape = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.shape = X.shape\n",
    "        return X.reshape(self.shape[0], -1)\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        return dA.reshape(*self.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】2次元畳み込み層の作成\n",
    "# 【問題2】2次元畳み込み後の出力サイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#今の所SimpleInitializer　と　SGDしか対応してません\n",
    "class Conv2d:\n",
    "    \"\"\"\n",
    "    convolutional layee\n",
    "    Parameters\n",
    "    ----------\n",
    "    filter_size : int\n",
    "      フィルターのサイズ\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, filter_h, filter_w, in_channel, initializer, optimizer, straid=1, pad=0, out_channel=1):\n",
    "        self.optimizer = optimizer\n",
    "        self.filter_h = filter_h\n",
    "        self.filter_w = filter_w\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(filter_h*filter_w*in_channel, out_channel).reshape(out_channel, in_channel, filter_h, filter_w)\n",
    "        self.B = initializer.B(out_channel).reshape(1,-1) #shape(1, out_cannel)\n",
    "        self.out_h = None\n",
    "        self.out_w = None\n",
    "        self.out_c = out_channel\n",
    "        self.straid = straid\n",
    "        self.Xcol = 0\n",
    "        self.dA = 0 #shape(batch_size, out_size)\n",
    "        self.dW = 0 \n",
    "        self.m = 0\n",
    "        self.h = 0\n",
    "        self.w = 0\n",
    "        self.c = in_channel\n",
    "        self.pad = pad\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, chanel, height, width)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, out_chanel, out_height, out_width)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        if X.ndim is 2:\n",
    "            X = X[np.newaxis, np.newaxis, :, :]\n",
    "        elif X.ndim is 3:\n",
    "            X = X[:, np.newaxis, :, :]\n",
    "            \n",
    "        self.m = X.shape[0]\n",
    "        self.h = X.shape[2]\n",
    "        self.w = X.shape[3]\n",
    "        \n",
    "        #out_sizeの計算\n",
    "        if self.out_h is None:\n",
    "            self.out_h = int((self.h + 2*self.pad - self.filter_h) / self.straid + 1)\n",
    "            self.out_w = int((self.w + 2*self.pad - self.filter_w) / self.straid + 1)\n",
    "        \n",
    "        #パディング\n",
    "        X = np.pad(X, [(0,0), (0,0), (self.pad, self.pad), (self.pad, self.pad)], 'constant')\n",
    "        \n",
    "        #m2col\n",
    "        col = np.zeros((self.m, self.c, self.filter_h, self.filter_w, self.out_h, self.out_w))\n",
    "        for y in range(self.filter_h):\n",
    "            y_max = y + self.straid*self.out_h\n",
    "            for x in range(self.filter_w):\n",
    "                x_max = x + self.straid*self.out_w\n",
    "                col[:, :, y, x, :, :] = X[:, :, y:y_max:self.straid, x:x_max:self.straid]\n",
    "                \n",
    "        col = col.transpose(0, 4, 5, 1, 2, 3).reshape(self.m*self.out_h*self.out_w, -1)\n",
    "        self.Xcol = col\n",
    "        self.Wcol = self.W.reshape(self.out_c, -1).T\n",
    "        A = np.dot(col, self.Wcol) + self.B.reshape(1,-1) #A shape(out_w*out_h*batch_size, out_c)\n",
    "        A = A.reshape(self.m, self.out_h, self.out_w, self.out_c).transpose(0,3,1,2)\n",
    "        return A\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size,　out_channel,　out_height,　out_width)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size,n_feture, in_channel)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        if dA.ndim is 1:\n",
    "            dA = dA[np.newaxis, :, np.newaxis]\n",
    "        elif dA.ndim is 2:\n",
    "            dA = dA[:, :, np.newaxis]\n",
    "        \n",
    "        self.dA = np.sum(np.sum(dA, axis=2),axis=2) #バイアスの計算用\n",
    "        #dAを shape(out_h*out_w*batchsize, out_channel)へ変形\n",
    "        dA = dA.transpose(0,2,3,1).reshape(-1, self.out_c)\n",
    "        #dWをWのshapeへ変形\n",
    "        self.dW = np.dot(self.Xcol.T, dA).T.reshape(self.out_c, self.c, self.filter_h, self.filter_w)\n",
    "        \n",
    "        dZcol = np.dot(dA, self.Wcol.T)\n",
    "        \n",
    "        #col2im\n",
    "        dZcol = dZcol.reshape(self.m, self.out_h, self.out_w, self.c, self.filter_h, self.filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "        img = np.zeros((self.m, self.c, self.h + 2*self.pad + self.straid - 1, self.out_w + 2*self.pad + self.straid - 1))\n",
    "        \n",
    "        for y in range(self.filter_h):\n",
    "            y_max = y + self.straid*self.out_h\n",
    "            for x in range(self.filter_w):\n",
    "                x_max = x + self.straid*self.out_w\n",
    "                img[:, :, y:y_max:self.straid, x:x_max:self.straid] += dZcol[:, :, y, x, :, :]\n",
    "                \n",
    "        dZ = img[:, :, self.pad:self.h + self.pad, self.pad:self.w + self.pad]\n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return dZ\n",
    "    \n",
    "    def get_out_put_size2D(n_h, n_w, pad, HF, WF, straid):\n",
    "        #一次元畳み込み後の出力サイズの計算\n",
    "        n_h = (n_h + 2*pad - HF) / straid + 1 \n",
    "        n_w = (n_w + 2*pad - WF) / straid + 1\n",
    "        return n_h, n_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】最大プーリング層の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, pool_h, pool_w, straid=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.straid = straid\n",
    "        self.pad = pad\n",
    "        self.m = None\n",
    "        self.c = None\n",
    "        self.h = None\n",
    "        self.w = None\n",
    "        self.out_h = None\n",
    "        self.out_w = None\n",
    "        self.x = None\n",
    "        self.arg_max = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.m, self.c, self.h, self.w = X.shape\n",
    "        if self.out_h is None:\n",
    "            self.out_h = int((self.h - self.pool_h) / self.straid + 1)\n",
    "            self.out_w =  int((self.w - self.pool_w) / self.straid + 1)\n",
    "\n",
    "        \n",
    "        #m2col\n",
    "        col = np.zeros((self.m, self.c, self.pool_h, self.pool_w, self.out_h, self.out_w))\n",
    "        for y in range(self.pool_h):\n",
    "            y_max = y + self.straid*self.out_h\n",
    "            for x in range(self.pool_w):\n",
    "                x_max = x + self.straid*self.out_w\n",
    "                col[:, :, y, x, :, :] = X[:, :, y:y_max:self.straid, x:x_max:self.straid]\n",
    "                \n",
    "        col = col.transpose(0, 4, 5, 1, 2, 3).reshape(self.m*self.out_h*self.out_w, -1)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "        #マックスとる\n",
    "        A = np.max(col, axis=1)\n",
    "        A = A.reshape(self.m, self.out_h, self.out_w, self.c).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        self.x = X\n",
    "        self.arg_max = np.argmax(col, axis=1)\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        dA = dA.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dA.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dA.flatten()\n",
    "        dmax = dmax.reshape(dA.shape + (pool_size,)) \n",
    "        \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dX = self.col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.straid, self.pad)\n",
    "        \n",
    "        \n",
    "        #col2im\n",
    "        #dcol = dcol.reshape(self.m, self.out_h, self.out_w, self.c, self.pool_h, self.pool_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "        #img = np.zeros((self.m, self.c, self.h + 2*self.pad + self.straid - 1, self.out_w + 2*self.pad + self.straid - 1))\n",
    "        \n",
    "        #for y in range(self.pool_h):\n",
    "            #y_max = y + self.straid*self.out_h\n",
    "            #for x in range(self.pool_w):\n",
    "                #x_max = x + self.straid*self.out_w\n",
    "                #img[:, :, y:y_max:self.straid, x:x_max:self.straid] += dcol[:, :, y, x, :, :]\n",
    "                \n",
    "        #dX = img[:, :, self.pad:self.h + self.pad, self.pad:self.w + self.pad]\n",
    "        \n",
    "        return dX\n",
    "\n",
    "    \n",
    "    def col2im(self, col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        col :\n",
    "        input_shape : 入力データの形状（例：(10, 1, 28, 28)）\n",
    "        filter_h :\n",
    "        filter_w\n",
    "        stride\n",
    "        pad\n",
    "        Returns\n",
    "        -------\n",
    "        \"\"\"\n",
    "        N, C, H, W = input_shape\n",
    "        out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "        out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "        col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "        img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "        for y in range(filter_h):\n",
    "            y_max = y + stride*out_h\n",
    "            for x in range(filter_w):\n",
    "                x_max = x + stride*out_w\n",
    "                img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "        return img[:, :, pad:H + pad, pad:W + pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#データのロード\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#フラットにする\n",
    "#X_train = x_train.reshape(-1, 784)\n",
    "#X_test = x_test.reshape(-1, 784)\n",
    "#スケール合わせ\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "#onehot\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "#sprit train and val\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_train.shape[1]\n",
    "model = ScratchDeepNeuralNetrowkClassifier2(n_features=n, batch_size=50, epoch=20, verbose=True)\n",
    "\n",
    "model.add_sim(Conv2d(3,3, in_channel=1, initializer=SimpleInitializer(), optimizer=SGD(lr=0.01), straid=1, pad=1, out_channel=64))\n",
    "model.add_sim(ReLU())\n",
    "model.add_sim(MaxPool2D(2,2, straid=2, pad=0))\n",
    "model.add_sim(Conv2d(3,3, in_channel=64, initializer=SimpleInitializer(), optimizer=SGD(lr=0.01), straid=1, pad=1, out_channel=64))\n",
    "model.add_sim(ReLU())\n",
    "model.add_sim(MaxPool2D(2,2, straid=2, pad=0))\n",
    "model.add_sim(Flatten())\n",
    "model.add_sim(FC(3136, 10, SimpleInitializer(), SGD(lr=0.01)))\n",
    "model.add_sim(Softmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 28, 28)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 train_loss: 2.3018933456371085 val_loss: 2.301672269097005 acc: 0.25666666666666665\n",
      "epoch:2 train_loss: 2.2999870640214777 val_loss: 2.300451667881612 acc: 0.17333333333333334\n",
      "epoch:3 train_loss: 2.29671252151794 val_loss: 2.2982832446241934 acc: 0.23333333333333334\n",
      "epoch:4 train_loss: 2.2897200626494674 val_loss: 2.293390084125797 acc: 0.2733333333333333\n",
      "epoch:5 train_loss: 2.271465035664093 val_loss: 2.2802327728803786 acc: 0.27\n",
      "epoch:6 train_loss: 2.2113171500482323 val_loss: 2.235278561078632 acc: 0.30333333333333334\n",
      "epoch:7 train_loss: 1.9592814993939005 val_loss: 2.0302725056578805 acc: 0.35\n",
      "epoch:8 train_loss: 1.7095264541614954 val_loss: 1.8354444968328745 acc: 0.4266666666666667\n",
      "epoch:9 train_loss: 1.0848990981395605 val_loss: 1.2756739112685953 acc: 0.6366666666666667\n",
      "epoch:10 train_loss: 1.0226896807100039 val_loss: 1.1916523026021606 acc: 0.6566666666666666\n",
      "epoch:11 train_loss: 0.7143204338823784 val_loss: 0.9070248099766053 acc: 0.7\n",
      "epoch:12 train_loss: 0.5691080965145793 val_loss: 0.7755421976588031 acc: 0.7766666666666666\n",
      "epoch:13 train_loss: 0.6438615344310797 val_loss: 0.8717659459603139 acc: 0.7333333333333333\n",
      "epoch:14 train_loss: 0.45119963773253385 val_loss: 0.666391363804484 acc: 0.7633333333333333\n",
      "epoch:15 train_loss: 0.37259151145036434 val_loss: 0.6109207592133251 acc: 0.78\n",
      "epoch:16 train_loss: 0.31740281501397605 val_loss: 0.6713729354387056 acc: 0.7933333333333333\n",
      "epoch:17 train_loss: 0.3196050079887398 val_loss: 0.7844623946420738 acc: 0.75\n",
      "epoch:18 train_loss: 0.378611293634446 val_loss: 0.9326825558953493 acc: 0.7266666666666667\n",
      "epoch:19 train_loss: 0.2378472878894171 val_loss: 0.6022126090161902 acc: 0.7966666666666666\n",
      "epoch:20 train_loss: 0.1377979353689146 val_loss: 0.5735369530119384 acc: 0.82\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train[:300],y_train[:300], X_val[:300], y_val[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_learning_curve()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
